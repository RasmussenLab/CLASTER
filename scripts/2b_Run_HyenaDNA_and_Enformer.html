
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2b. BENCHMARKING CLASTER WITH HYENA-DNA AND ENFORMER</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'scripts/2b_Run_HyenaDNA_and_Enformer';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title"></p>
  
</a></div>
        <div class="sidebar-primary-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/RasmussenLab/CLASTER" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Claster
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorial:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="0_Tutorial.html">TUTORIAL</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/RasmussenLab/CLASTER/blob/master/docs/scripts/2b_Run_HyenaDNA_and_Enformer.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/RasmussenLab/CLASTER" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/RasmussenLab/CLASTER/edit/master/docs/scripts/2b_Run_HyenaDNA_and_Enformer.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/scripts/2b_Run_HyenaDNA_and_Enformer.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1><center> 2b. BENCHMARKING CLASTER WITH HYENA-DNA AND ENFORMER <center></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyena-dna">1. Hyena-DNA:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enformer">2. Enformer</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="b-benchmarking-claster-with-hyena-dna-and-enformer">
<h1><center> 2b. BENCHMARKING CLASTER WITH HYENA-DNA AND ENFORMER <center><a class="headerlink" href="#b-benchmarking-claster-with-hyena-dna-and-enformer" title="Link to this heading">#</a></h1>
<section id="hyena-dna">
<h2>1. Hyena-DNA:<a class="headerlink" href="#hyena-dna" title="Link to this heading">#</a></h2>
<p>The following is an adaptation of the open source code provided by the authors of Hyena-DNA, who are to be credited for it.</p>
<p>The paper can be found as:
Eric Nguyen and Michael Poli and Marjan Faizi and Armin Thomas and Callum Birch-Sykes and Michael Wornow and Aman Patel and Clayton Rabideau and Stefano Massaroli and Yoshua Bengio and Stefano Ermon and Stephen A. Baccus and Chris Ré, <em>HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution</em> , 2023.</p>
<p>https://doi.org/10.48550/arXiv.2306.15794</p>
<p>The original public colab notebook can be found here:</p>
<p>https://colab.research.google.com/drive/1wyVEQd4R3HYLTUOXEEQmp_I8aNC_aLhL</p>
<p><strong>Edits:</strong>
The goal was to add a head to the Hyena-DNA backbone. We tried obtaining only the embeddings and then adding the head on top of those, but we could not predict EU-seq profiles from the pretrained embeddings.</p>
<p>The structure of the backbone remains untouched. We added custom regression heads aimed to</p>
<ul class="simple">
<li><p>Perform dimensionality reduction from the high dimensional embeddings.</p></li>
<li><p>Link the resulting sequence representations to our outputs, i.e. EU-seq levels at a kbp resolution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w">  </span>einops<span class="w"> </span>torchvision<span class="w"> </span><span class="nv">transformers</span><span class="o">==</span><span class="m">4</span>.26.1<span class="w"> </span>nvidia-ml-py3<span class="w"> </span>genomic-benchmarks<span class="w"> </span>OmegaConf
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: einops in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (0.7.0)
Requirement already satisfied: torchvision in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (0.17.1)
Collecting transformers==4.26.1
  Using cached transformers-4.26.1-py3-none-any.whl.metadata (100 kB)
Requirement already satisfied: nvidia-ml-py3 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (7.352.0)
Requirement already satisfied: genomic-benchmarks in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (0.0.9)
Requirement already satisfied: OmegaConf in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (2.3.0)
Requirement already satisfied: filelock in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (3.13.3)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.11.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (0.22.0)
Requirement already satisfied: numpy&gt;=1.17 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (1.26.4)
Requirement already satisfied: packaging&gt;=20.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (24.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (2023.12.25)
Requirement already satisfied: requests in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (2.31.0)
Collecting tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 (from transformers==4.26.1)
  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Requirement already satisfied: tqdm&gt;=4.27 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from transformers==4.26.1) (4.66.2)
Requirement already satisfied: torch==2.2.1 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torchvision) (2.2.1)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torchvision) (10.2.0)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (4.10.0)
Requirement already satisfied: sympy in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (1.12)
Requirement already satisfied: networkx in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (3.2.1)
Requirement already satisfied: jinja2 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (3.1.3)
Requirement already satisfied: fsspec in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (2024.3.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from torch==2.2.1-&gt;torchvision) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch==2.2.1-&gt;torchvision) (12.4.99)
Requirement already satisfied: biopython&gt;=1.79 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from genomic-benchmarks) (1.83)
Requirement already satisfied: pip&gt;=20.0.1 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from genomic-benchmarks) (23.3.1)
Requirement already satisfied: pandas&gt;=1.1.4 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from genomic-benchmarks) (2.2.1)
Requirement already satisfied: gdown&gt;=4.2.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from genomic-benchmarks) (5.1.0)
Requirement already satisfied: yarl in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from genomic-benchmarks) (1.9.4)
Requirement already satisfied: antlr4-python3-runtime==4.9.* in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from OmegaConf) (4.9.3)
Requirement already satisfied: beautifulsoup4 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from gdown&gt;=4.2.0-&gt;genomic-benchmarks) (4.12.3)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from pandas&gt;=1.1.4-&gt;genomic-benchmarks) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from pandas&gt;=1.1.4-&gt;genomic-benchmarks) (2024.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from pandas&gt;=1.1.4-&gt;genomic-benchmarks) (2024.1)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from requests-&gt;transformers==4.26.1) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from requests-&gt;transformers==4.26.1) (3.6)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from requests-&gt;transformers==4.26.1) (2.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from requests-&gt;transformers==4.26.1) (2024.2.2)
Requirement already satisfied: multidict&gt;=4.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from yarl-&gt;genomic-benchmarks) (6.0.5)
Requirement already satisfied: six&gt;=1.5 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&gt;=1.1.4-&gt;genomic-benchmarks) (1.16.0)
Requirement already satisfied: soupsieve&gt;1.2 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from beautifulsoup4-&gt;gdown&gt;=4.2.0-&gt;genomic-benchmarks) (2.5)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from jinja2-&gt;torch==2.2.1-&gt;torchvision) (2.1.5)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from requests[socks]-&gt;gdown&gt;=4.2.0-&gt;genomic-benchmarks) (1.7.1)
Requirement already satisfied: mpmath&gt;=0.19 in /maps/projects/rasmussen/data/enhancer_logic_project/claster_env/lib/python3.11/site-packages (from sympy-&gt;torch==2.2.1-&gt;torchvision) (1.3.0)
Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)
Using cached tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)
Installing collected packages: tokenizers, transformers
  Attempting uninstall: tokenizers
    Found existing installation: tokenizers 0.15.2
    Uninstalling tokenizers-0.15.2:
      Successfully uninstalled tokenizers-0.15.2
  Attempting uninstall: transformers
    Found existing installation: transformers 4.39.1
    Uninstalling transformers-4.39.1:
      Successfully uninstalled transformers-4.39.1
<span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">eir-dl 0.1.42 requires tokenizers&lt;0.16.0,&gt;=0.15.0, but you have tokenizers 0.13.3 which is incompatible.</span>
<span class=" -Color -Color-Red">eir-dl 0.1.42 requires transformers&lt;5.0.0,&gt;=4.34.0, but you have transformers 4.26.1 which is incompatible.</span>
Successfully installed tokenizers-0.13.3 transformers-4.26.1
</pre></div>
</div>
</div>
</div>
<p><strong>Train and test HyenaDNA</strong></p>
<blockquote>
<div><p>Of note:</p>
<ul class="simple">
<li><p>CLASTER_HYENA_Dataset. Data class for our specific dataset.</p></li>
<li><p>ConvLinearModel. Model head, i.e. decoder, added on top of Hyena’s backbone embeddings to decode them into our outputs. It first applies a sequence length reduction by averaging over 128 bp (Enformer’s resolution) and then applies dropout, a set of convolutional filters (10) and an MLP to map to the targets under a softplus activation.</p></li>
</ul>
<p><em>Hyperparams:</em></p>
<ul class="simple">
<li><p>input_depth = 256</p></li>
<li><p>input_length = 32768 #160000</p></li>
<li><p>output_length = (15*2+1)# <em>2 only one condition now #(57</em>2+1)*2</p></li>
<li><p>avg_pool_size= (1,128) #(depth_axis, seqlen_axis)</p></li>
<li><p>kernel_size = 9</p></li>
<li><p>dilation=2</p></li>
<li><p>stride = 2</p></li>
<li><p>padding= (dilation * (kernel_size - 1)) // 2</p></li>
<li><p>dropout_rate=.3</p></li>
<li><p>hidden_depth=10</p></li>
</ul>
</div></blockquote>
<p>At the very end of the following cell you can choose whether you want to get the embeddings of the pretrained models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uncomment if we want to get pretrained embeddings</span>
<span class="n">inference_single_sequential</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">savepath</span><span class="p">,</span> <span class="n">checkpoint_folder</span><span class="p">)</span>
</pre></div>
</div>
<p>Or fine-tune both head and backbone together:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uncomment if we want to train and test HyenaDNA:</span>
<span class="n">run_train_CLASTER_HYENA</span><span class="p">()</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> Hyena_DNA_Esrum.py 

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Python file containing the HyenaDNA ipynb cells stacked:</span>
<span class="sd">https://colab.research.google.com/drive/1wyVEQd4R3HYLTUOXEEQmp_I8aNC_aLhL</span>
<span class="sd">All credit is for the original developers.</span>

<span class="sd">We added custom heads and modified and added training functions accordingly.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">#@title Installs</span>
<span class="c1"># ! pip install einops</span>
<span class="c1"># ! pip install torchvision</span>
<span class="c1"># ! pip install transformers==4.26.1</span>
<span class="c1"># ! pip install genomic-benchmarks</span>
<span class="c1"># ! pip install OmegaConf</span>


<span class="c1">#@title Imports</span>
<span class="c1"># for HyenaDNA specifically</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">einops</span> <span class="kn">import</span> <span class="n">rearrange</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torchvision.ops</span> <span class="kn">import</span> <span class="n">StochasticDepth</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">subprocess</span>


<span class="n">checkpoints_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;../checkpoints/&quot;</span><span class="p">)</span>
<span class="n">checkpoints_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">#@title Hyena layer</span>

<span class="k">def</span> <span class="nf">fftconv</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    We apply a convolution through the fourier domain (from the Convolution Theorem)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">seqlen</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">fft_size</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">seqlen</span>

    <span class="n">k_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">fft_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">fft_size</span>
    <span class="n">u_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">k</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">n</span><span class="o">=</span><span class="n">fft_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span> <span class="n">k_f</span> <span class="o">=</span> <span class="n">k_f</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft</span><span class="p">(</span><span class="n">u_f</span> <span class="o">*</span> <span class="n">k_f</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">fft_size</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;forward&#39;</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">seqlen</span><span class="p">]</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">u</span> <span class="o">*</span> <span class="n">D</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">u</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span>
<span class="k">def</span> <span class="nf">mul_sum</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">q</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">OptimModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Interface for Module that allows registering buffers/parameters with configurable optimizer hyperparameters &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Register a tensor with a configurable learning rate and 0 weight decay&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">lr</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">tensor</span><span class="p">))</span>

            <span class="n">optim</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">optim</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
            <span class="k">if</span> <span class="n">wd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">optim</span><span class="p">[</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">wd</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">),</span> <span class="s2">&quot;_optim&quot;</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Sin</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The Sin activation function for the Hyena Filter function.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">train_freq</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">freq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span> <span class="k">if</span> <span class="n">train_freq</span> <span class="k">else</span> <span class="n">w</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">freq</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">PositionalEmbedding</span><span class="p">(</span><span class="n">OptimModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">lr_pos_emb</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Complex exponential positional embeddings for Hyena filters.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="c1"># The time embedding fed to the filteres is normalized so that t_f = 1</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="c1"># 1, L, 1</span>

        <span class="k">if</span> <span class="n">emb_dim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">bands</span> <span class="o">=</span> <span class="p">(</span><span class="n">emb_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="c1"># To compute the right embeddings we use the &quot;proper&quot; linspace</span>
        <span class="n">t_rescaled</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">w</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">t_rescaled</span> <span class="o">/</span> <span class="n">seq_len</span> <span class="c1"># 1, L, 1</span>

        <span class="n">f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">bands</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bands</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="n">f</span> <span class="o">*</span> <span class="n">w</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">imag</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_pos_emb</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">[:,</span> <span class="p">:</span><span class="n">L</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">[:,</span> <span class="p">:</span><span class="n">L</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">ExponentialModulation</span><span class="p">(</span><span class="n">OptimModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The window function applied to the output of the (MLP) filter function.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">d_model</span><span class="p">,</span>
        <span class="n">fast_decay_pct</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">slow_decay_pct</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">target</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">modulation_lr</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">modulate</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">shift</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modulate</span> <span class="o">=</span> <span class="n">modulate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">=</span> <span class="n">shift</span>
        <span class="n">max_decay</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">target</span><span class="p">)</span> <span class="o">/</span> <span class="n">fast_decay_pct</span>
        <span class="n">min_decay</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">target</span><span class="p">)</span> <span class="o">/</span> <span class="n">slow_decay_pct</span>
        <span class="n">deltas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">min_decay</span><span class="p">,</span> <span class="n">max_decay</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;deltas&quot;</span><span class="p">,</span> <span class="n">deltas</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">modulation_lr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">modulate</span><span class="p">:</span>
            <span class="n">decay</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">deltas</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">decay</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">HyenaFilter</span><span class="p">(</span><span class="n">OptimModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">d_model</span><span class="p">,</span>
            <span class="n">emb_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="c1"># dim of input to MLP, augments with positional encoding</span>
            <span class="n">order</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="c1"># width of the implicit MLP</span>
            <span class="n">fused_fft_conv</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">seq_len</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
            <span class="n">lr_pos_emb</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">w</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># frequency of periodic activations</span>
            <span class="n">wd</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1"># weight decay of kernel parameters</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_inner_mlps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implicit long filter with modulation.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_model: number of channels in the input</span>
<span class="sd">            emb_dim: dimension of the positional encoding (`emb_dim` - 1) // 2 is the number of bands</span>
<span class="sd">            order: width of the FFN</span>
<span class="sd">            num_inner_mlps: number of inner linear layers inside filter MLP</span>

<span class="sd">        Note:</span>
<span class="sd">            filter_dropout is not implemented</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fused_fft_conv</span> <span class="o">=</span> <span class="n">fused_fft_conv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">act</span> <span class="o">=</span> <span class="n">Sin</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_dim</span> <span class="o">=</span> <span class="n">emb_dim</span>
        <span class="k">assert</span> <span class="n">emb_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">emb_dim</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;emb_dim must be odd and greater or equal to 3 (time, sine and cosine)&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span> <span class="o">=</span> <span class="n">PositionalEmbedding</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">lr_pos_emb</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">implicit_filter</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">order</span><span class="p">),</span>
            <span class="n">act</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_inner_mlps</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">implicit_filter</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">order</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">implicit_filter</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">act</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">implicit_filter</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">modulation</span> <span class="o">=</span> <span class="n">ExponentialModulation</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">implicit_filter</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">optim</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">wd</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">lr</span><span class="p">}</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">name</span><span class="p">),</span> <span class="s2">&quot;_optim&quot;</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">implicit_filter</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">modulation</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

        <span class="c1"># Ensure compatibility with filters that return a tuple</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">tuple</span> <span class="k">else</span> <span class="n">k</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">fftconv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>


<span class="k">class</span> <span class="nc">HyenaOperator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">d_model</span><span class="p">,</span>
            <span class="n">l_max</span><span class="p">,</span>
            <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">filter_order</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">filter_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="o">**</span><span class="n">filter_args</span><span class="p">,</span>
        <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Hyena operator described in the paper https://arxiv.org/pdf/2302.10866.pdf</span>

<span class="sd">        Args:</span>
<span class="sd">            d_model (int): Dimension of the input and output embeddings (width of the layer)</span>
<span class="sd">            l_max: (int): Maximum input sequence length. Defaults to None</span>
<span class="sd">            order: (int): Depth of the Hyena recurrence. Defaults to 2</span>
<span class="sd">            dropout: (float): Dropout probability. Defaults to 0.0</span>
<span class="sd">            filter_dropout: (float): Dropout probability for the filter. Defaults to 0.0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l_max</span> <span class="o">=</span> <span class="n">l_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">=</span> <span class="n">order</span>
        <span class="n">inner_width</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">*</span> <span class="p">(</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">inner_width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">short_filter</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span>
            <span class="n">inner_width</span><span class="p">,</span>
            <span class="n">inner_width</span><span class="p">,</span>
            <span class="mi">3</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">groups</span><span class="o">=</span><span class="n">inner_width</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filter_fn</span> <span class="o">=</span> <span class="n">HyenaFilter</span><span class="p">(</span>
            <span class="n">d_model</span> <span class="o">*</span> <span class="p">(</span><span class="n">order</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">order</span><span class="o">=</span><span class="n">filter_order</span><span class="p">,</span>
            <span class="n">seq_len</span><span class="o">=</span><span class="n">l_max</span><span class="p">,</span>
            <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">filter_dropout</span><span class="p">,</span>
            <span class="o">**</span><span class="n">filter_args</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">l_filter</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_max</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="s1">&#39;b l d -&gt; b d l&#39;</span><span class="p">)</span>

        <span class="n">uc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">short_filter</span><span class="p">(</span><span class="n">u</span><span class="p">)[</span><span class="o">...</span><span class="p">,:</span><span class="n">l_filter</span><span class="p">]</span>
        <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">uc</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter_fn</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">l_filter</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s1">&#39;l (o d) -&gt; o d l&#39;</span><span class="p">,</span> <span class="n">o</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_fn</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="s1">&#39;(o d) -&gt; o d&#39;</span><span class="p">,</span> <span class="n">o</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">o</span><span class="p">,</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:])):</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">x_i</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter_fn</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">l_filter</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">[</span><span class="n">o</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">[</span><span class="n">o</span><span class="p">])</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;b d l -&gt; b l d&#39;</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="c1">#@title Self-Attention (alternative)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">If you&#39;d like to try the HyenaDNA model using attention instead, you can. ie,</span>
<span class="sd">use a regular decoder only Transformer.</span>

<span class="sd">Borrowed from the FlashAttention library by Tri Dao.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Implement the scaled dot product attention with softmax.</span>
<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">        softmax_scale: The temperature to use for the softmax attention.</span>
<span class="sd">                      (default: 1/sqrt(d_keys) where d_keys is computed at</span>
<span class="sd">                      runtime)</span>
<span class="sd">        attention_dropout: The dropout rate to apply to the attention</span>
<span class="sd">                           (default: 0.0)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">softmax_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal</span> <span class="o">=</span> <span class="n">causal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax_scale</span> <span class="o">=</span> <span class="n">softmax_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_p</span> <span class="o">=</span> <span class="n">attention_dropout</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qkv</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Implements the multihead softmax attention.</span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">            qkv: The tensor containing the query, key, and value. (B, S, 3, H, D)</span>
<span class="sd">            causal: if passed, will override self.causal</span>
<span class="sd">            key_padding_mask: boolean mask to apply to the attention weights. True means to keep,</span>
<span class="sd">                False means to mask out. (B, S)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seqlen</span> <span class="o">=</span> <span class="n">qkv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">qkv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">causal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">causal</span> <span class="k">if</span> <span class="n">causal</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">causal</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">qkv</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">softmax_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_scale</span> <span class="ow">or</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bthd,bshd-&gt;bhts&#39;</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="n">softmax_scale</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">padding_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seqlen</span><span class="p">),</span> <span class="o">-</span><span class="mf">10000.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">scores</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                      <span class="n">device</span><span class="o">=</span><span class="n">scores</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">padding_mask</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">+</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">padding_mask</span><span class="p">,</span> <span class="s1">&#39;b s -&gt; b 1 1 s&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">causal</span><span class="p">:</span>
            <span class="c1"># &quot;triu_tril_cuda_template&quot; not implemented for &#39;BFloat16&#39;</span>
            <span class="c1"># So we have to construct the mask in float</span>
            <span class="n">causal_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">seqlen</span><span class="p">,</span> <span class="n">seqlen</span><span class="p">),</span> <span class="o">-</span><span class="mf">10000.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">scores</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">+</span> <span class="n">causal_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">scores</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">attention</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">attention_drop</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_p</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bhts,bshd-&gt;bthd&#39;</span><span class="p">,</span> <span class="n">attention_drop</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="k">class</span> <span class="nc">MHA</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi-head self-attention and cross-attention</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                 <span class="n">softmax_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">layer_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dwconv</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">return_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            return_residual: whether to return the input x along with the output. This is for</span>
<span class="sd">                performance reason: for post-norm architecture, returning the input allows us</span>
<span class="sd">                to fuse the backward of nn.Linear with the residual connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal</span> <span class="o">=</span> <span class="n">causal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_idx</span> <span class="o">=</span> <span class="n">layer_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span> <span class="o">=</span> <span class="n">dwconv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span> <span class="o">=</span> <span class="n">return_residual</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;self.kdim must be divisible by num_heads&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">//</span> <span class="n">num_heads</span>

        <span class="n">linear_cls</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span>
        <span class="n">linear_resid_cls</span> <span class="o">=</span> <span class="n">LinearResidual</span>
        <span class="n">inner_attn_cls</span> <span class="o">=</span>  <span class="n">SelfAttention</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wqkv</span> <span class="o">=</span> <span class="n">linear_cls</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wqkv</span> <span class="o">=</span> <span class="n">linear_resid_cls</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dwconv_qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                        <span class="n">groups</span><span class="o">=</span><span class="mi">3</span> <span class="o">*</span> <span class="n">embed_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inner_attn</span> <span class="o">=</span> <span class="n">inner_attn_cls</span><span class="p">(</span><span class="n">causal</span><span class="o">=</span><span class="n">causal</span><span class="p">,</span> <span class="n">softmax_scale</span><span class="o">=</span><span class="n">softmax_scale</span><span class="p">,</span>
                                         <span class="n">attention_dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

        <span class="c1"># output projection always have the bias (for now)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">linear_cls</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Arguments:</span>
<span class="sd">            x: (batch, seqlen, hidden_dim) (where hidden_dim = num heads * head dim) if</span>
<span class="sd">                cu_seqlens is None and max_seqlen is None, else (total, hidden_dim) where total</span>
<span class="sd">                is the is the sum of the sequence lengths in the batch.</span>
<span class="sd">            cu_seqlens: (batch_size + 1,), dtype torch.int32. The cumulative sequence lengths</span>
<span class="sd">                of the sequences in the batch, used to index into x. Only applicable when using</span>
<span class="sd">                FlashAttention.</span>
<span class="sd">            max_seqlen: int. Maximum sequence length in the batch.</span>
<span class="sd">            key_padding_mask: boolean mask, True means to keep, False means to mask out.</span>
<span class="sd">                (batch, seqlen). Only applicable when not using FlashAttention.</span>
<span class="sd">            mixer_subset: for cross-attention only. If not None, will take a subset of x</span>
<span class="sd">                before applying the query projection. Useful for e.g., ViT where we only care</span>
<span class="sd">                about the CLS token in the last layer.</span>
<span class="sd">            inference_params: for generation. Adapted from Megatron-LM (and Apex)</span>
<span class="sd">            https://github.com/NVIDIA/apex/blob/3ff1a10f72ec07067c4e44759442329804ac5162/apex/transformer/testing/standalone_transformer_lm.py#L470</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">({</span><span class="s1">&#39;key_padding_mask&#39;</span><span class="p">:</span> <span class="n">key_padding_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">})</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span><span class="p">:</span>
            <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wqkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">qkv</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Wqkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dwconv</span><span class="p">:</span>
            <span class="n">qkv</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dwconv_qkv</span><span class="p">(</span><span class="n">rearrange</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="s1">&#39;b s d -&gt; b d s&#39;</span><span class="p">))[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
                            <span class="s1">&#39;b d s -&gt; b s d&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="s1">&#39;... (three h d) -&gt; ... three h d&#39;</span><span class="p">,</span> <span class="n">three</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>

        <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_attn</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">rearrange</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="s1">&#39;... h d -&gt; ... (h d)&#39;</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span> <span class="k">else</span> <span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c1">#@title MLP layer</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The MLP layer after the mixer layer (HyenaOperator).</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">Mlp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">gelu</span><span class="p">,</span>
                 <span class="n">return_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        From https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/modules/mlp.py</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="n">hidden_features</span> <span class="o">=</span> <span class="n">hidden_features</span> <span class="ow">or</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span> <span class="o">=</span> <span class="n">return_residual</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span> <span class="k">else</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="c1">#@title Block layer (Hyena + MLP layers)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A block consists of a Mixer layer (Hyena or attention), and a MLP layer.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">LinearResidual</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrap nn.Linear to return the residual as well. For compatibility with FusedDense.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="nb">input</span>

<span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">mixer_cls</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mlp_cls</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_cls</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
                 <span class="n">dropout_cls</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">,</span> <span class="n">prenorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">resid_dropout1</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">resid_dropout2</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                 <span class="n">drop_path1</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">drop_path2</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                 <span class="n">return_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">residual_in_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        From https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/modules/block.py</span>
<span class="sd">        For prenorm=True, this Block has a slightly different structure compared to a regular</span>
<span class="sd">        prenorm Transformer block.</span>
<span class="sd">        The standard block is: LN -&gt; MHA -&gt; Dropout -&gt; Add -&gt; LN -&gt; MLP -&gt; Dropout -&gt; Add.</span>
<span class="sd">        [Ref: https://arxiv.org/abs/2002.04745]</span>
<span class="sd">        Here we have: Dropout -&gt; Add -&gt; LN -&gt; MHA -&gt; Dropout -&gt; Add -&gt; LN -&gt; MLP, returning both</span>
<span class="sd">        the hidden_states (output of the MLP) and the residual.</span>
<span class="sd">        This is for performance reasons, as we can fuse the dropout, add and LayerNorm.</span>
<span class="sd">        The residual needs to be provided (except for the very first block).</span>
<span class="sd">        For prenorm=False, this Block has the same structure as a regular postnorm Transformer</span>
<span class="sd">        block: MHA -&gt; Dropout -&gt; Add -&gt; LN -&gt; MLP -&gt; Dropout -&gt; Add -&gt; LN.</span>
<span class="sd">        return_residual: whether each of the sub-layers (mixer and mlp) will return the residual.</span>
<span class="sd">        This is for performance reason: for post-norm architecture, returning the input allows us</span>
<span class="sd">        to fuse the backward of nn.Linear with the residual connectio</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prenorm</span> <span class="o">=</span> <span class="n">prenorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span> <span class="o">=</span> <span class="n">return_residual</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residual_in_fp32</span> <span class="o">=</span> <span class="n">residual_in_fp32</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_in_fp32</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenorm</span><span class="p">,</span> <span class="s1">&#39;residual_in_fp32 is only compatible with prenorm=True&#39;</span>
        <span class="k">if</span> <span class="n">mixer_cls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mixer_cls</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">MHA</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="n">dim</span> <span class="o">//</span> <span class="mi">64</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mlp_cls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mlp_cls</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">Mlp</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="mi">4</span> <span class="o">*</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mixer</span> <span class="o">=</span> <span class="n">mixer_cls</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">dropout_cls</span><span class="p">(</span><span class="n">resid_dropout1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_path1</span> <span class="o">=</span> <span class="n">StochasticDepth</span><span class="p">(</span><span class="n">drop_path1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;row&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">norm_cls</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">mlp_cls</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">dropout_cls</span><span class="p">(</span><span class="n">resid_dropout2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">drop_path2</span> <span class="o">=</span> <span class="n">StochasticDepth</span><span class="p">(</span><span class="n">drop_path2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;row&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">norm_cls</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">residual</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">mixer_subset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mixer_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the encoder layer.</span>
<span class="sd">        Args:</span>
<span class="sd">            hidden_states: the sequence to the encoder layer (required).</span>
<span class="sd">            residual: if postnorm, residual=None, If prenorm, hidden_states = Attn/MLP(LN(residual))</span>
<span class="sd">            mixer_subset: for cross-attention only. If not None, will take a subset of x</span>
<span class="sd">                before applying the query projection. Useful for e.g., ViT where we only care</span>
<span class="sd">                about the CLS token in the last layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenorm</span><span class="p">:</span>
            <span class="n">dropped</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
            <span class="n">residual</span> <span class="o">=</span> <span class="p">(</span><span class="n">dropped</span> <span class="o">+</span> <span class="n">residual</span><span class="p">)</span> <span class="k">if</span> <span class="n">residual</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dropped</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">residual</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_in_fp32</span><span class="p">:</span>
                <span class="n">residual</span> <span class="o">=</span> <span class="n">residual</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mixer_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">mixer_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="n">mixer_subset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">mixer_kwargs</span><span class="p">[</span><span class="s1">&#39;mixer_subset&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mixer_subset</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixer</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="o">**</span><span class="n">mixer_kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mixer_subset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">residual</span> <span class="o">=</span> <span class="n">residual</span><span class="p">[:,</span> <span class="n">mixer_subset</span><span class="p">]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">):</span>
                <span class="n">dropped</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_path2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
                <span class="n">residual</span> <span class="o">=</span> <span class="p">(</span><span class="n">dropped</span> <span class="o">+</span> <span class="n">residual</span><span class="p">)</span> <span class="k">if</span> <span class="n">residual</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dropped</span>
                <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">residual</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_in_fp32</span><span class="p">:</span>
                    <span class="n">residual</span> <span class="o">=</span> <span class="n">residual</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

                <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">residual</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">residual</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="n">mixer_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixer</span><span class="p">(</span>
                <span class="n">hidden_states</span><span class="p">,</span> <span class="o">**</span><span class="p">(</span><span class="n">mixer_kwargs</span> <span class="k">if</span> <span class="n">mixer_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{})</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span><span class="p">:</span>  <span class="c1"># mixer out is actually a pair here</span>
                <span class="n">mixer_out</span><span class="p">,</span> <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">mixer_out</span>

            <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">drop_path1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">mixer_out</span><span class="p">))</span>
                                        <span class="o">+</span> <span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">):</span>
                <span class="n">mlp_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_residual</span><span class="p">:</span>  <span class="c1"># mlp out is actually a pair here</span>
                    <span class="n">mlp_out</span><span class="p">,</span> <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">mlp_out</span>

                <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">drop_path2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">mlp_out</span><span class="p">))</span>
                                            <span class="o">+</span> <span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">hidden_states</span>

<span class="k">def</span> <span class="nf">create_mixer_cls</span><span class="p">(</span><span class="n">layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">attn_layer_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">attn_layer_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="n">attn_layer_idx</span><span class="p">:</span>
        <span class="n">causal</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">attn_cfg</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">attn_cfg</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;causal&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="n">mha_cls</span> <span class="o">=</span> <span class="n">MHA</span>

        <span class="n">mixer_cls</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">mha_cls</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="n">causal</span><span class="p">,</span> <span class="n">layer_idx</span><span class="o">=</span><span class="n">layer_idx</span><span class="p">,</span>
                            <span class="o">**</span><span class="p">(</span><span class="n">attn_cfg</span> <span class="k">if</span> <span class="n">attn_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}),</span><span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># mixer_cls = instantiate(registry.layer, layer, partial=True, layer_idx=layer_idx, **factory_kwargs)</span>

        <span class="n">mixer_cls</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">HyenaOperator</span><span class="p">,</span> <span class="o">**</span><span class="n">layer</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mixer_cls</span>

<span class="k">def</span> <span class="nf">create_mlp_cls</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_inner</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
    <span class="n">inner_dim</span> <span class="o">=</span> <span class="n">d_inner</span> <span class="k">if</span> <span class="n">d_inner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">d_model</span>

    <span class="n">mlp_cls</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">Mlp</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="n">inner_dim</span><span class="p">,</span>
                          <span class="n">activation</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">gelu</span><span class="p">,</span> <span class="n">approximate</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">),</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mlp_cls</span>


<span class="k">def</span> <span class="nf">create_block</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_inner</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_layer_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">attn_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer_norm_epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
                 <span class="n">resid_dropout1</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">resid_dropout2</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">residual_in_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">layer_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
    <span class="n">mixer_cls</span> <span class="o">=</span> <span class="n">create_mixer_cls</span><span class="p">(</span><span class="n">layer</span><span class="o">=</span><span class="n">layer</span><span class="p">,</span>
                                 <span class="n">attn_layer_idx</span><span class="o">=</span><span class="n">attn_layer_idx</span><span class="p">,</span>
                                 <span class="n">attn_cfg</span><span class="o">=</span><span class="n">attn_cfg</span><span class="p">,</span> <span class="n">layer_idx</span><span class="o">=</span><span class="n">layer_idx</span><span class="p">,</span>
                                 <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
    <span class="n">mlp_cls</span> <span class="o">=</span> <span class="n">create_mlp_cls</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_inner</span><span class="o">=</span><span class="n">d_inner</span><span class="p">,</span>
                             <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
    <span class="n">norm_cls</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">layer_norm_epsilon</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">mixer_cls</span><span class="p">,</span> <span class="n">mlp_cls</span><span class="p">,</span> <span class="n">norm_cls</span><span class="o">=</span><span class="n">norm_cls</span><span class="p">,</span>
                  <span class="n">prenorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">resid_dropout1</span><span class="o">=</span><span class="n">resid_dropout1</span><span class="p">,</span> <span class="n">resid_dropout2</span><span class="o">=</span><span class="n">resid_dropout2</span><span class="p">,</span><span class="n">residual_in_fp32</span><span class="o">=</span><span class="n">residual_in_fp32</span><span class="p">)</span>
    <span class="n">block</span><span class="o">.</span><span class="n">layer_idx</span> <span class="o">=</span> <span class="n">layer_idx</span>
    <span class="k">return</span> <span class="n">block</span>


<span class="c1"># https://github.com/huggingface/transformers/blob/c28d04e9e252a1a099944e325685f14d242ecdcd/src/transformers/models/gpt2/modeling_gpt2.py#L454</span>
<span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">n_layer</span><span class="p">,</span> <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">rescale_prenorm_residual</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                  <span class="n">glu_act</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">initializer_range</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">rescale_prenorm_residual</span><span class="p">:</span>
        <span class="c1"># Reinitialize selected weights subject to the OpenAI GPT-2 Paper Scheme:</span>
        <span class="c1">#   &gt; A modified initialization which accounts for the accumulation on the residual path with model depth. Scale</span>
        <span class="c1">#   &gt; the weights of residual layers at initialization by a factor of 1/√N where N is the # of residual layers.</span>
        <span class="c1">#   &gt;   -- GPT-2 :: https://openai.com/blog/better-language-models/</span>
        <span class="c1">#</span>
        <span class="c1"># Reference (Megatron-LM): https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;out_proj.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;fc2.weight&quot;</span><span class="p">]:</span>
                <span class="c1"># Special Scaled Initialization --&gt; There are 2 Layer Norms per Transformer Block</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">initializer_range</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_layer</span><span class="p">))</span>
            <span class="c1"># If using GLU activation for now, we scale the std by 2</span>
            <span class="k">elif</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;output_linear.0.weight&quot;</span><span class="p">]:</span>
                <span class="c1"># Special Scaled Initialization --&gt; There are 2 Layer Norms per Transformer Block</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">glu_act</span><span class="p">:</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">initializer_range</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_layer</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">out_features</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="c1"># Multiplying the first half of the matrix by 2 since sigmoid scales it down by 0.5</span>
                    <span class="c1"># on average.</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">p</span><span class="p">[:</span><span class="n">out_features</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">initializer_range</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_layer</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1">#@title Backbone model (stack of blocks)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A backbone model consists of a stack of blocks. If you use attention, then</span>
<span class="sd">positional embeddings are included. When using Hyena, then the pos emb</span>
<span class="sd">revert to doing nothing.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">GPT2Embeddings</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">max_position_embeddings</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">word_embed_proj_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            If max_position_embeddings &lt;= 0, there&#39;s no position embeddings</span>
<span class="sd">            If word_embe_proj_dim is not None (e.g., OPT-350m), we embed to that dimension</span>
<span class="sd">                the project up to embed_dim</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">word_embed_proj_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
                                                <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">project_in</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">word_embed_proj_dim</span><span class="p">,</span>
                                                <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">project_in</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">word_embed_proj_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                        <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_position_embeddings</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span>
                                                    <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            input_ids: (batch, seqlen)</span>
<span class="sd">            position_ids: (batch, seqlen)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seqlen</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_in</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seqlen</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">input_ids</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeddings</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span>
        <span class="k">return</span> <span class="n">embeddings</span>

<span class="k">class</span> <span class="nc">LMBackbone</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_layer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">d_inner</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">process_group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">attn_layer_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">resid_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">embed_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">layer_norm_epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="n">initializer_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">residual_in_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span> <span class="o">=</span> <span class="n">process_group</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">residual_in_fp32</span> <span class="o">=</span> <span class="n">residual_in_fp32</span>
        <span class="c1"># note max_position_embeddings is 0 for Hyena, and therefore isn&#39;t used</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">GPT2Embeddings</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">max_position_embeddings</span><span class="p">,</span>
                                             <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">create_block</span><span class="p">(</span>
            <span class="n">d_model</span><span class="p">,</span> <span class="n">d_inner</span><span class="o">=</span><span class="n">d_inner</span><span class="p">,</span>
            <span class="n">layer</span><span class="o">=</span><span class="n">layer</span><span class="p">,</span> <span class="n">attn_layer_idx</span><span class="o">=</span><span class="n">attn_layer_idx</span><span class="p">,</span>
            <span class="n">attn_cfg</span><span class="o">=</span><span class="n">attn_cfg</span><span class="p">,</span> <span class="n">layer_norm_epsilon</span><span class="o">=</span><span class="n">layer_norm_epsilon</span><span class="p">,</span>
            <span class="n">resid_dropout1</span><span class="o">=</span><span class="n">embed_dropout</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">resid_dropout</span><span class="p">,</span>
            <span class="n">resid_dropout2</span><span class="o">=</span><span class="n">resid_dropout</span><span class="p">,</span> <span class="n">residual_in_fp32</span><span class="o">=</span><span class="n">residual_in_fp32</span><span class="p">,</span><span class="n">layer_idx</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
            <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">,</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layer</span><span class="p">)])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">drop_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">resid_dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">layer_norm_epsilon</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">_init_weights</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
                           <span class="o">**</span><span class="p">(</span><span class="n">initializer_cfg</span> <span class="k">if</span> <span class="n">initializer_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{})))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1">#print(&quot;Before embeddings:&quot;, torch.cuda.memory_allocated(device=&#39;cuda&#39;))</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,)</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1">#print(hidden_states.shape, hidden_states.dtype)</span>
        <span class="c1">#print(&quot;After embeddings:&quot;, torch.cuda.memory_allocated(device=&#39;cuda&#39;))</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">hidden_states</span><span class="p">,</span> <span class="n">residual</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">residual</span><span class="p">)</span>
            <span class="c1">#print(hidden_states.shape)</span>
            <span class="c1">#print(torch.cuda.memory_allocated(device=&#39;cuda&#39;))</span>

        <span class="n">dropped</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_f</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="p">(</span><span class="n">dropped</span> <span class="o">+</span> <span class="n">residual</span><span class="p">)</span> <span class="k">if</span> <span class="n">residual</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">dropped</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span><span class="p">(</span><span class="n">residual</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">hidden_states</span>


<span class="c1">#@title Decoder head layer</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A simple decoder head (using MLP) to predict a sequence level classification.</span>
<span class="sd">You have the option to average across all the tokens in a sequence or using the</span>
<span class="sd">&quot;last&quot; token to classify.  At least, those 2 worked best for us, but we provide</span>
<span class="sd">other &quot;modes&quot; as well.</span>

<span class="sd">We only need this for classification.  Otherwise we&#39;ll use the hidden</span>
<span class="sd">states of the backbone as embeddings.</span>

<span class="sd">&quot;&quot;&quot;</span>


<span class="k">class</span> <span class="nc">SequenceDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">l_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_lengths</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;last&quot;</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span> <span class="k">if</span> <span class="n">d_output</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">l_output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l_output</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">l_output</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Equivalent to getting an output of length 1 and then squeezing</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l_output</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">l_output</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l_output</span> <span class="o">=</span> <span class="n">l_output</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">use_lengths</span> <span class="o">=</span> <span class="n">use_lengths</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;ragged&#39;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="n">use_lengths</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">l_output</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        x: (n_batch, l_seq, d_model)</span>
<span class="sd">        Returns: (n_batch, l_output, d_output)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">l_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">l_output</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>  <span class="c1"># Override by pass in</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Grab entire output</span>
                <span class="n">l_output</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">squeeze</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">l_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l_output</span>
            <span class="n">squeeze</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">squeeze</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span>
            <span class="n">restrict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">l_output</span><span class="p">:,</span> <span class="p">:]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;first&quot;</span><span class="p">:</span>
            <span class="n">restrict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">l_output</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;pool&quot;</span><span class="p">:</span>
            <span class="n">restrict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
                <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                    <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
                <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">l_output</span><span class="p">:,</span> <span class="p">:]</span>

            <span class="k">def</span> <span class="nf">restrict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">L</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">l_output</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="p">(</span><span class="n">l_output</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
                    <span class="n">c</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
                    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">-</span> <span class="n">c</span>  <span class="c1"># (B, l_output, D)</span>
                    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">denom</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                    <span class="n">L</span> <span class="o">-</span> <span class="n">l_output</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">L</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="n">denom</span>
                <span class="k">return</span> <span class="n">s</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
            <span class="n">restrict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">l_output</span><span class="p">:,</span> <span class="p">:]</span>
            <span class="c1"># TODO use same restrict function as pool case</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;ragged&#39;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;lengths must be provided for ragged mode&quot;</span>
            <span class="c1"># remove any additional padding (beyond max length of any sequence in the batch)</span>
            <span class="n">restrict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">),</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Mode must be [&#39;last&#39; | &#39;first&#39; | &#39;pool&#39; | &#39;sum&#39;]&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Restrict to actual length of sequence</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lengths</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">restrict</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">length</span><span class="p">,</span> <span class="p">:])</span>
                    <span class="k">for</span> <span class="n">out</span><span class="p">,</span> <span class="n">length</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">lengths</span><span class="p">)</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">restrict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">squeeze</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Ignore all length logic</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ConvLinearModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_depth</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span><span class="n">avg_pool_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">hidden_depth</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvLinearModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 2D Average Pooling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">avg_pool_size</span><span class="p">)</span>

        <span class="c1"># Dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>

        <span class="c1"># Adjust the input depth and sequence length based on the 2D pooling</span>
        <span class="n">new_depth</span> <span class="o">=</span> <span class="n">input_depth</span> <span class="o">//</span> <span class="n">avg_pool_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">new_seq_length</span> <span class="o">=</span> <span class="n">input_length</span> <span class="o">//</span> <span class="n">avg_pool_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># 1D Convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">new_depth</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">hidden_depth</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">)</span>

        <span class="c1"># Calculate the output length after convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_length_after_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_output_length</span><span class="p">(</span><span class="n">new_seq_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>

        <span class="c1"># Fully connected layer with calculated input size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_depth</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length_after_conv</span><span class="p">,</span> <span class="n">output_length</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">calculate_output_length</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">input_length</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">-</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Reshape x to (batch_size, 1, input_depth, seq_length) for 2D avg pooling</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1">#print(x.shape)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
       <span class="c1"># print(x.shape)</span>

        <span class="c1"># Reshape back to (batch_size, new_depth, new_seq_length) for 1D convolution</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>

        <span class="c1"># Apply 1D convolution</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Apply dropout to the inputs of the final layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Reshape x for the linear layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Pass through the fully connected layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Apply Softplus activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="c1">#@title Model (backbone + head)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Putting it all together, the model consists of a backbone model</span>
<span class="sd">and a decoder head (you can turn off head for embeddings only too).</span>

<span class="sd">Here we use a simple head to do multi-classification, but</span>
<span class="sd">can also swap the head to do next token prediction too.  We defer to the main</span>
<span class="sd">HyenaDNA for that code, since pretraining with next token prediction isn&#39;t quite</span>
<span class="sd">feasible on colab.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">HyenaDNAModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_layer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">d_inner</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_layer_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">resid_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">embed_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">layer_norm_epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="n">initializer_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">residual_in_fp32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">pad_vocab_size_multiple</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">use_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                 <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">factory_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="n">dtype</span><span class="p">}</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">vocab_size</span> <span class="o">%</span> <span class="n">pad_vocab_size_multiple</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">vocab_size</span> <span class="o">+=</span> <span class="n">pad_vocab_size_multiple</span> <span class="o">-</span> <span class="p">(</span><span class="n">vocab_size</span> <span class="o">%</span> <span class="n">pad_vocab_size_multiple</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">use_head</span> <span class="o">=</span> <span class="n">use_head</span>

        <span class="c1"># check if layer (config) has d_model (HF code differs from main Safari code)</span>
        <span class="k">if</span> <span class="s1">&#39;d_model&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">layer</span><span class="p">:</span>
            <span class="n">layer</span><span class="p">[</span><span class="s1">&#39;d_model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">LMBackbone</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">d_inner</span><span class="o">=</span><span class="n">d_inner</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">layer</span><span class="o">=</span><span class="n">layer</span><span class="p">,</span> <span class="n">attn_layer_idx</span><span class="o">=</span><span class="n">attn_layer_idx</span><span class="p">,</span> <span class="n">attn_cfg</span><span class="o">=</span><span class="n">attn_cfg</span><span class="p">,</span>
            <span class="n">max_position_embeddings</span><span class="o">=</span><span class="n">max_position_embeddings</span><span class="p">,</span>
            <span class="n">resid_dropout</span><span class="o">=</span><span class="n">resid_dropout</span><span class="p">,</span> <span class="n">embed_dropout</span><span class="o">=</span><span class="n">embed_dropout</span><span class="p">,</span>
            <span class="n">layer_norm_epsilon</span><span class="o">=</span><span class="n">layer_norm_epsilon</span><span class="p">,</span>
            <span class="n">initializer_cfg</span><span class="o">=</span><span class="n">initializer_cfg</span><span class="p">,</span> <span class="n">residual_in_fp32</span><span class="o">=</span><span class="n">residual_in_fp32</span><span class="p">,</span>
            <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

        <span class="c1"># we only need a head if doing classification, otherwise we&#39;ll use the</span>
        <span class="c1"># hidden states as embeddings</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_head</span><span class="p">:</span>

            <span class="c1">#self.head = SequenceDecoder(d_model=d_model, d_output=1, l_output=230, mode=&#39;pool&#39;)</span>
            <span class="n">input_depth</span> <span class="o">=</span> <span class="mi">256</span>
            <span class="n">input_length</span> <span class="o">=</span> <span class="mi">32768</span> <span class="c1">#160000</span>
            <span class="n">output_length</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="c1"># *2 only one condition now #(57*2+1)*2</span>
            <span class="n">avg_pool_size</span><span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">128</span><span class="p">)</span> <span class="c1">#(depth_axis, seqlen_axis)</span>
            <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">9</span>
            <span class="n">dilation</span><span class="o">=</span><span class="mi">2</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">padding</span><span class="o">=</span> <span class="p">(</span><span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">.3</span>
            <span class="n">hidden_depth</span><span class="o">=</span><span class="mi">10</span>
    

            <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">ConvLinearModel</span><span class="p">(</span><span class="n">input_depth</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span><span class="n">avg_pool_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">hidden_depth</span><span class="p">)</span>
        
        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">_init_weights</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span>
                           <span class="o">**</span><span class="p">(</span><span class="n">initializer_cfg</span> <span class="k">if</span> <span class="n">initializer_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{})))</span>

        <span class="c1"># if self.use_head:</span>
        <span class="c1">#     self.tie_weights()</span>

    <span class="c1"># def tie_weights(self):</span>
    <span class="c1">#     self.head.weight = self.backbone.embeddings.word_embeddings.weight</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span> <span class="c1"># state for the repo interface</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_head</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hidden_states</span>


<span class="c1">#@title Huggingface Pretrained Wrapper</span>
<span class="c1"># for Huggingface integration, we use a wrapper class around the model</span>
<span class="c1"># to load weights</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">PreTrainedModel</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">PretrainedConfig</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="k">def</span> <span class="nf">inject_substring</span><span class="p">(</span><span class="n">orig_str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Hack to handle matching keys between models trained with and without</span>
<span class="sd">    gradient checkpointing.&quot;&quot;&quot;</span>

    <span class="c1"># modify for mixer keys</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;\.mixer&quot;</span>
    <span class="n">injection</span> <span class="o">=</span> <span class="s2">&quot;.mixer.layer&quot;</span>

    <span class="n">modified_string</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">injection</span><span class="p">,</span> <span class="n">orig_str</span><span class="p">)</span>

    <span class="c1"># modify for mlp keys</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;\.mlp&quot;</span>
    <span class="n">injection</span> <span class="o">=</span> <span class="s2">&quot;.mlp.layer&quot;</span>

    <span class="n">modified_string</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">injection</span><span class="p">,</span> <span class="n">modified_string</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">modified_string</span>

<span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="n">scratch_dict</span><span class="p">,</span> <span class="n">pretrained_dict</span><span class="p">,</span> <span class="n">checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Loads pretrained (backbone only) weights into the scratch state dict.</span>

<span class="sd">    scratch_dict: dict, a state dict from a newly initialized HyenaDNA model</span>
<span class="sd">    pretrained_dict: dict, a state dict from the pretrained ckpt</span>
<span class="sd">    checkpointing: bool, whether the gradient checkpoint flag was used in the</span>
<span class="sd">    pretrained model ckpt. This slightly changes state dict keys, so we patch</span>
<span class="sd">    that if used.</span>

<span class="sd">    return:</span>
<span class="sd">    dict, a state dict with the pretrained weights loaded (head is scratch)</span>

<span class="sd">    # loop thru state dict of scratch</span>
<span class="sd">    # find the corresponding weights in the loaded model, and set it</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># need to do some state dict &quot;surgery&quot;</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">scratch_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="s1">&#39;backbone&#39;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
            <span class="c1"># the state dicts differ by one prefix, &#39;.model&#39;, so we add that</span>
            <span class="n">key_loaded</span> <span class="o">=</span> <span class="s1">&#39;model.&#39;</span> <span class="o">+</span> <span class="n">key</span>
            <span class="c1"># breakpoint()</span>
            <span class="c1"># need to add an extra &quot;.layer&quot; in key</span>
            <span class="k">if</span> <span class="n">checkpointing</span><span class="p">:</span>
                <span class="n">key_loaded</span> <span class="o">=</span> <span class="n">inject_substring</span><span class="p">(</span><span class="n">key_loaded</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">scratch_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">pretrained_dict</span><span class="p">[</span><span class="n">key_loaded</span><span class="p">]</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;key mismatch in the state dicts!&#39;</span><span class="p">)</span>

    <span class="c1"># scratch_dict has been updated</span>
    <span class="k">return</span> <span class="n">scratch_dict</span>

<span class="k">def</span> <span class="nf">download_files</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
    <span class="c1"># Create the output directory if it doesn&#39;t exist</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Download the files</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
        <span class="c1"># Get the filename from the URL</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="c1"># Write the downloaded content to the file</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">copyfileobj</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">raw</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">filename</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to download files from </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">download_pretrained_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
    <span class="n">hf_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;https://huggingface.co/LongSafari/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">/resolve/main/config.json&#39;</span>
    <span class="n">config_file</span> <span class="o">=</span> <span class="n">download_files</span><span class="p">(</span><span class="n">hf_url</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">))</span>
    
    <span class="n">weights_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;https://huggingface.co/LongSafari/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">/resolve/main/weights.ckpt&#39;</span>
    <span class="n">weights_file</span> <span class="o">=</span> <span class="n">download_files</span><span class="p">(</span><span class="n">weights_url</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">config</span><span class="p">,</span> <span class="n">weights_file</span>


<span class="k">class</span> <span class="nc">HyenaDNAPreTrainedModel</span><span class="p">(</span><span class="n">PreTrainedModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained</span>
<span class="sd">    models.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_model_prefix</span> <span class="o">=</span> <span class="s2">&quot;hyenadna&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                        <span class="n">path</span><span class="p">,</span>
                        <span class="n">model_name</span><span class="p">,</span>
                        <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span>
                        <span class="n">use_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="p">):</span>
        <span class="c1"># first check if it is a local path</span>
        <span class="n">pretrained_model_name_or_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">)</span> <span class="ow">and</span> <span class="n">download</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="s1">&#39;config.json&#39;</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># hf_url = f&#39;https://huggingface.co/LongSafari/{model_name}&#39;</span>
            <span class="c1"># print(&quot;here again&quot;)</span>
            <span class="c1"># subprocess.run(f&#39;rm -rf {pretrained_model_name_or_path}&#39;, shell=True)</span>
            <span class="c1"># command = f&#39;mkdir -p {path} &amp;&amp; cd {path} &amp;&amp; git lfs install &amp;&amp; git clone {hf_url}&#39;</span>
            <span class="c1"># subprocess.run(command, shell=True)</span>
            <span class="n">config</span><span class="p">,</span> <span class="n">weights_file</span> <span class="o">=</span> <span class="n">download_pretrained_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="s1">&#39;config.json&#39;</span><span class="p">)))</span>

        <span class="n">scratch_model</span> <span class="o">=</span> <span class="n">HyenaDNAModel</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">,</span> <span class="n">use_head</span><span class="o">=</span><span class="n">use_head</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span>  <span class="c1"># the new model format</span>
        <span class="n">loaded_ckpt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="s1">&#39;weights.ckpt&#39;</span><span class="p">),</span>
            <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># need to load weights slightly different if using gradient checkpointing</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;checkpoint_mixer&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="n">checkpointing</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;checkpoint_mixer&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">or</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;checkpoint_mixer&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">checkpointing</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># grab state dict from both and load weights</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">load_weights</span><span class="p">(</span><span class="n">scratch_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">loaded_ckpt</span><span class="p">[</span><span class="s1">&#39;state_dict&#39;</span><span class="p">],</span> <span class="n">checkpointing</span><span class="o">=</span><span class="n">checkpointing</span><span class="p">)</span>

        <span class="c1"># scratch model has now been updated</span>
        <span class="n">scratch_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loaded pretrained weights ok!&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scratch_model</span>

<span class="c1">#@title Tokenizer</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Just a simple character level tokenizer.</span>

<span class="sd">From: https://github.com/dariush-bahrami/character-tokenizer/blob/master/charactertokenizer/core.py</span>

<span class="sd">CharacterTokenzier for Hugging Face Transformers.</span>
<span class="sd">This is heavily inspired from CanineTokenizer in transformers package.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">transformers.tokenization_utils</span> <span class="kn">import</span> <span class="n">AddedToken</span><span class="p">,</span> <span class="n">PreTrainedTokenizer</span>

<span class="k">class</span> <span class="nc">CharacterTokenizer</span><span class="p">(</span><span class="n">PreTrainedTokenizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">characters</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">model_max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding_side</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Character tokenizer for Hugging Face transformers.</span>
<span class="sd">        Args:</span>
<span class="sd">            characters (Sequence[str]): List of desired characters. Any character which</span>
<span class="sd">                is not included in this list will be replaced by a special token called</span>
<span class="sd">                [UNK] with id=6. Following are list of all of the special tokens with</span>
<span class="sd">                their corresponding ids:</span>
<span class="sd">                    &quot;[CLS]&quot;: 0</span>
<span class="sd">                    &quot;[SEP]&quot;: 1</span>
<span class="sd">                    &quot;[BOS]&quot;: 2</span>
<span class="sd">                    &quot;[MASK]&quot;: 3</span>
<span class="sd">                    &quot;[PAD]&quot;: 4</span>
<span class="sd">                    &quot;[RESERVED]&quot;: 5</span>
<span class="sd">                    &quot;[UNK]&quot;: 6</span>
<span class="sd">                an id (starting at 7) will be assigned to each character.</span>
<span class="sd">            model_max_length (int): Model maximum sequence length.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">characters</span> <span class="o">=</span> <span class="n">characters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">=</span> <span class="n">model_max_length</span>
        <span class="n">bos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="s2">&quot;[BOS]&quot;</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">eos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">sep_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">cls_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="s2">&quot;[CLS]&quot;</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">pad_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">unk_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="s2">&quot;[UNK]&quot;</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">mask_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="s2">&quot;[MASK]&quot;</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
            <span class="n">eos_token</span><span class="o">=</span><span class="n">sep_token</span><span class="p">,</span>
            <span class="n">sep_token</span><span class="o">=</span><span class="n">sep_token</span><span class="p">,</span>
            <span class="n">cls_token</span><span class="o">=</span><span class="n">cls_token</span><span class="p">,</span>
            <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="n">mask_token</span><span class="o">=</span><span class="n">mask_token</span><span class="p">,</span>
            <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
            <span class="n">add_prefix_space</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">model_max_length</span><span class="o">=</span><span class="n">model_max_length</span><span class="p">,</span>
            <span class="n">padding_side</span><span class="o">=</span><span class="n">padding_side</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_str_to_int</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;[CLS]&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;[SEP]&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;[BOS]&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s2">&quot;[MASK]&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s2">&quot;[PAD]&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s2">&quot;[RESERVED]&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">&quot;[UNK]&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
            <span class="o">**</span><span class="p">{</span><span class="n">ch</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">7</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">characters</span><span class="p">)},</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_int_to_str</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_str_to_int</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_vocab_str_to_int</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_convert_token_to_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_str_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_str_to_int</span><span class="p">[</span><span class="s2">&quot;[UNK]&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_convert_id_to_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocab_int_to_str</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">convert_tokens_to_string</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_inputs_with_special_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">sep</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">]</span>
        <span class="bp">cls</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">cls</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">sep</span>
        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">sep</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">get_special_tokens_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">already_has_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">already_has_special_tokens</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_special_tokens_mask</span><span class="p">(</span>
                <span class="n">token_ids_0</span><span class="o">=</span><span class="n">token_ids_0</span><span class="p">,</span>
                <span class="n">token_ids_1</span><span class="o">=</span><span class="n">token_ids_1</span><span class="p">,</span>
                <span class="n">already_has_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_1</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">create_token_type_ids_from_sequences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">sep</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">]</span>
        <span class="bp">cls</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">cls</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">sep</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">sep</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;char_ords&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">ord</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">characters</span><span class="p">],</span>
            <span class="s2">&quot;model_max_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;CharacterTokenizer&quot;</span><span class="p">:</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;characters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;char_ords&quot;</span><span class="p">]]</span>
        <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;model_max_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;model_max_length&quot;</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">cfg_file</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_directory</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;tokenizer_config.json&quot;</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cfg_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">cfg_file</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_directory</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;tokenizer_config.json&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">cfg_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>


<span class="c1">#@title GenomicBenchmark dataset</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The GenomicBenchmarks dataset will automatically download to /contents on colab.</span>
<span class="sd">There are 8 datasets to choose from.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1">#from genomic_benchmarks.loc2seq import download_dataset</span>
<span class="c1">#from genomic_benchmarks.data_check import is_downloaded</span>


<span class="c1"># helper functions</span>
<span class="k">def</span> <span class="nf">exists</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

<span class="k">def</span> <span class="nf">coin_flip</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span>


<span class="n">string_complement_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">:</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">:</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span><span class="p">}</span>
<span class="c1"># augmentation</span>
<span class="k">def</span> <span class="nf">string_reverse_complement</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
    <span class="n">rev_comp</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">base</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">base</span> <span class="ow">in</span> <span class="n">string_complement_map</span><span class="p">:</span>
            <span class="n">rev_comp</span> <span class="o">+=</span> <span class="n">string_complement_map</span><span class="p">[</span><span class="n">base</span><span class="p">]</span>
        <span class="c1"># if bp not complement map, use the same bp</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rev_comp</span> <span class="o">+=</span> <span class="n">base</span>
    <span class="k">return</span> <span class="n">rev_comp</span>


<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">genomic_benchmarks.loc2seq</span> <span class="kn">import</span> <span class="n">download_dataset</span>
<span class="kn">from</span> <span class="nn">genomic_benchmarks.data_check</span> <span class="kn">import</span> <span class="n">is_downloaded</span>


<span class="k">class</span> <span class="nc">GenomicBenchmarkDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Loop thru bed file, retrieve (chr, start, end), query fasta file for sequence.</span>
<span class="sd">    Returns a generator that retrieves the sequence.</span>

<span class="sd">    Genomic Benchmarks Dataset, from:</span>
<span class="sd">    https://github.com/ML-Bioinfo-CEITEC/genomic_benchmarks</span>


<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">split</span><span class="p">,</span>
        <span class="n">max_length</span><span class="p">,</span>
        <span class="n">dataset_name</span><span class="o">=</span><span class="s1">&#39;human_enhancers_cohn&#39;</span><span class="p">,</span>
        <span class="n">d_output</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1"># default binary classification</span>
        <span class="n">dest_path</span><span class="o">=</span><span class="s2">&quot;./data/&quot;</span><span class="p">,</span> <span class="c1"># default for colab</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">use_padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">add_eos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">rc_aug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">return_augs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_padding</span> <span class="o">=</span> <span class="n">use_padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_name</span> <span class="o">=</span> <span class="n">tokenizer_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_augs</span> <span class="o">=</span> <span class="n">return_augs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_eos</span> <span class="o">=</span> <span class="n">add_eos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_output</span> <span class="o">=</span> <span class="n">d_output</span>  <span class="c1"># needed for decoder to grab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rc_aug</span> <span class="o">=</span> <span class="n">rc_aug</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_downloaded</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">cache_path</span><span class="o">=</span><span class="n">dest_path</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;downloading </span><span class="si">{}</span><span class="s2"> to </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">dest_path</span><span class="p">))</span>
            <span class="n">download_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dest_path</span><span class="o">=</span><span class="n">dest_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;already downloaded </span><span class="si">{}</span><span class="s2">-</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">))</span>

        <span class="c1"># use Path object</span>
        <span class="n">base_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">dest_path</span><span class="p">)</span> <span class="o">/</span> <span class="n">dataset_name</span> <span class="o">/</span> <span class="n">split</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">all_paths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">label_mapper</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">base_path</span><span class="o">.</span><span class="n">iterdir</span><span class="p">()):</span>
            <span class="n">label_mapper</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">stem</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

        <span class="k">for</span> <span class="n">label_type</span> <span class="ow">in</span> <span class="n">label_mapper</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">base_path</span> <span class="o">/</span> <span class="n">label_type</span><span class="p">)</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_mapper</span><span class="p">[</span><span class="n">label_type</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_paths</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">txt_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_paths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">txt_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">content</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># apply rc_aug here if using</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rc_aug</span> <span class="ow">and</span> <span class="n">coin_flip</span><span class="p">():</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">string_reverse_complement</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">seq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
            <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_padding</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># add cls and eos token (+2)</span>
        <span class="n">seq</span> <span class="o">=</span> <span class="n">seq</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>  <span class="c1"># get input_ids</span>

        <span class="c1"># need to handle eos here</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_eos</span><span class="p">:</span>
            <span class="c1"># append list seems to be faster than append tensor</span>
            <span class="n">seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">)</span>

        <span class="c1"># convert to tensor</span>
        <span class="n">seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>

        <span class="c1"># need to wrap in list</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">y</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">seq</span><span class="p">,</span> <span class="n">target</span>

<span class="c1">############################## Our Datasets ###############</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">Bio</span> <span class="kn">import</span> <span class="n">SeqIO</span>
<span class="kn">import</span> <span class="nn">zlib</span>
<span class="kn">import</span> <span class="nn">sys</span>


<span class="k">class</span> <span class="nc">CLASTER_HYENA_Dataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Returns a generator that retrieves the sequence.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fasta_file</span><span class="p">,</span>
        <span class="n">csv_file</span><span class="p">,</span>
        <span class="n">max_length</span><span class="p">,</span>
        <span class="n">target_columns</span><span class="p">,</span>
        <span class="n">d_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">use_padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">add_eos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">rc_aug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">return_augs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_padding</span> <span class="o">=</span> <span class="n">use_padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_name</span> <span class="o">=</span> <span class="n">tokenizer_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_augs</span> <span class="o">=</span> <span class="n">return_augs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_eos</span> <span class="o">=</span> <span class="n">add_eos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rc_aug</span> <span class="o">=</span> <span class="n">rc_aug</span>

        <span class="c1"># Read CSV file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targets_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_file</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;ID&#39;</span><span class="p">)</span>

        <span class="c1"># Extract continuous target vectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">continuous_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets_df</span><span class="p">[</span><span class="n">target_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

        <span class="c1"># Read FASTA file and store sequences and corresponding IDs in a dictionary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sequences</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">SeqIO</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">fasta_file</span><span class="p">,</span> <span class="s2">&quot;fasta&quot;</span><span class="p">):</span>
            <span class="n">header_parts</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">description</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">)</span>
            <span class="n">seq_id</span> <span class="o">=</span> <span class="n">header_parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Remove &#39;&gt;&#39;</span>
            <span class="n">sequence</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">seq</span><span class="p">)</span>


            <span class="c1"># Create reverse complement and store it with the &quot;_flipped&quot; identifier</span>
            <span class="n">reverse_complement</span> <span class="o">=</span> <span class="n">string_reverse_complement</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
            <span class="n">flipped_seq_id</span> <span class="o">=</span> <span class="n">seq_id</span> <span class="o">+</span> <span class="s2">&quot;_flipped&quot;</span>
            <span class="c1"># Crop distances:</span>
            <span class="n">crop_dist</span> <span class="o">=</span> <span class="p">(</span><span class="mi">160000</span><span class="o">-</span><span class="mi">32768</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span>
            <span class="c1"># Store the sequence with its ID</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sequences</span><span class="p">[</span><span class="n">seq_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">sequence</span><span class="p">[</span><span class="n">crop_dist</span><span class="p">:</span><span class="o">-</span><span class="n">crop_dist</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sequences</span><span class="p">[</span><span class="n">flipped_seq_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">reverse_complement</span><span class="p">[</span><span class="n">crop_dist</span><span class="p">:</span><span class="o">-</span><span class="n">crop_dist</span><span class="p">]</span>

        <span class="c1"># Extract IDs from the target CSV file (assuming the ID column is named &#39;ID&#39;)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets_df</span><span class="o">.</span><span class="n">index</span>

        <span class="c1"># Match sequence IDs with target IDs and store their indices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matched_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">seq_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span><span class="p">)</span> <span class="k">if</span> <span class="n">seq_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequences</span><span class="p">]</span>

        <span class="c1"># Determine the number of output dimensions if not provided</span>
        <span class="k">if</span> <span class="n">d_output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_output</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_columns</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_output</span> <span class="o">=</span> <span class="n">d_output</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">matched_indices</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># Get sequence ID and retrieve the sequence</span>
        <span class="n">seq_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_ids</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">matched_indices</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequences</span><span class="p">[</span><span class="n">seq_id</span><span class="p">]</span>

        <span class="c1"># Get continuous target vector</span>
        <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">continuous_targets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">matched_indices</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>

        <span class="c1"># Tokenize sequence</span>
        <span class="n">encoded_sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">sequence</span><span class="p">,</span>
            <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_padding</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>    <span class="c1"># Get input_ids</span>

        <span class="c1"># Need to handle eos here</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_eos</span><span class="p">:</span>
            <span class="c1"># Append list seems to be faster than append tensor</span>
            <span class="n">encoded_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">)</span>

        <span class="c1"># Convert to tensor</span>
        <span class="n">encoded_sequence</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">encoded_sequence</span><span class="p">)</span>

        <span class="c1"># Convert target to tensor</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">encoded_sequence</span><span class="p">,</span> <span class="n">target</span>


<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="n">LOG_FILENAME</span> <span class="o">=</span> <span class="s2">&quot;../checkpoints/hyenadna_32k.log&quot;</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">LOG_FILENAME</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>  

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">We provide simple training code for the GenomicBenchmark datasets.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Training loop.&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># sum up batch loss</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Train Epoch: </span><span class="si">{}</span><span class="se">\t</span><span class="s1">Average Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">))</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;../checkpoints/hyenadna-small-32k-seqlen/model_32k.pt&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test loop.&quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># sum up batch loss</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">targets</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">target</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()])</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">output</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()])</span> 
            
    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;Hyena_finetunned_targets.npy&quot;</span><span class="p">,</span><span class="n">targets</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;Hyena_finetunned_predictions.npy&quot;</span><span class="p">,</span><span class="n">predictions</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.6f}</span><span class="se">\t</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">PreTrainedModel</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">PretrainedConfig</span>
<span class="kn">import</span> <span class="nn">nvidia_smi</span>

<span class="k">def</span> <span class="nf">run_train</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Main entry point for training.  Select the dataset name and metadata, as</span>
<span class="sd">    well as model and training args, and you&#39;re off to the genomic races!</span>

<span class="sd">    ### GenomicBenchmarks Metadata</span>
<span class="sd">    # there are 8 datasets in this suite, choose 1 at a time, with their corresponding settings</span>
<span class="sd">    # name                                num_seqs        num_classes     median len    std</span>
<span class="sd">    # dummy_mouse_enhancers_ensembl       1210            2               2381          984.4</span>
<span class="sd">    # demo_coding_vs_intergenomic_seqs    100_000         2               200           0</span>
<span class="sd">    # demo_human_or_worm                  100_000         2               200           0</span>
<span class="sd">    # human_enhancers_cohn                27791           2               500           0</span>
<span class="sd">    # human_enhancers_ensembl             154842          2               269           122.6</span>
<span class="sd">    # human_ensembl_regulatory            289061          3               401           184.3</span>
<span class="sd">    # human_nontata_promoters             36131           2               251           0</span>
<span class="sd">    # human_ocr_ensembl                   174756          2               315           108.1</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># experiment settings:</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># ~100 seems fine</span>
    <span class="n">max_length</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># max len of sequence of dataset (of what you want)</span>
    <span class="n">use_padding</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">dataset_name</span> <span class="o">=</span> <span class="s1">&#39;human_enhancers_cohn&#39;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">6e-4</span>  <span class="c1"># good default for Hyena</span>
    <span class="n">rc_aug</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># reverse complement augmentation</span>
    <span class="n">add_eos</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># add end of sentence token</span>
    <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="c1"># for fine-tuning, only the &#39;tiny&#39; model can fit on colab</span>
    <span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s1">&#39;hyenadna-tiny-1k-seqlen&#39;</span>  <span class="c1"># use None if training from scratch</span>

    <span class="c1"># we need these for the decoder head, if using</span>
    <span class="n">use_head</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="c1"># you can override with your own backbone config here if you want,</span>
    <span class="c1"># otherwise we&#39;ll load the HF one by default</span>
    <span class="n">backbone_cfg</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using device:&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># instantiate the model (pretrained here)</span>
    <span class="k">if</span> <span class="n">pretrained_model_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;hyenadna-tiny-1k-seqlen&#39;</span><span class="p">]:</span>
        <span class="c1"># use the pretrained Huggingface wrapper instead</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">HyenaDNAPreTrainedModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="s1">&#39;./checkpoints&#39;</span><span class="p">,</span>
            <span class="n">pretrained_model_name</span><span class="p">,</span>
            <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">backbone_cfg</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">use_head</span><span class="o">=</span><span class="n">use_head</span><span class="p">,</span>
            <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># from scratch</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">HyenaDNAModel</span><span class="p">(</span><span class="o">**</span><span class="n">backbone_cfg</span><span class="p">,</span> <span class="n">use_head</span><span class="o">=</span><span class="n">use_head</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span>

    <span class="c1"># create tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CharacterTokenizer</span><span class="p">(</span>
        <span class="n">characters</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">],</span>  <span class="c1"># add DNA characters, N is uncertain</span>
        <span class="n">model_max_length</span><span class="o">=</span><span class="n">max_length</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># to account for special tokens, like EOS</span>
        <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># we handle special tokens elsewhere</span>
        <span class="n">padding_side</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="c1"># since HyenaDNA is causal, we pad on the left</span>
    <span class="p">)</span>

    <span class="c1"># create datasets</span>
    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">GenomicBenchmarkDataset</span><span class="p">(</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span><span class="p">,</span>
        <span class="n">use_padding</span> <span class="o">=</span> <span class="n">use_padding</span><span class="p">,</span>
        <span class="n">split</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">dataset_name</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">,</span>
        <span class="n">rc_aug</span><span class="o">=</span><span class="n">rc_aug</span><span class="p">,</span>
        <span class="n">add_eos</span><span class="o">=</span><span class="n">add_eos</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">ds_test</span> <span class="o">=</span> <span class="n">GenomicBenchmarkDataset</span><span class="p">(</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span><span class="p">,</span>
        <span class="n">use_padding</span> <span class="o">=</span> <span class="n">use_padding</span><span class="p">,</span>
        <span class="n">split</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">dataset_name</span><span class="o">=</span><span class="n">dataset_name</span><span class="p">,</span>
        <span class="n">rc_aug</span><span class="o">=</span><span class="n">rc_aug</span><span class="p">,</span>
        <span class="n">add_eos</span><span class="o">=</span><span class="n">add_eos</span><span class="p">,</span>
    <span class="p">)</span>


    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># loss function</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># create optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
        <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">run_train_CLASTER_HYENA</span><span class="p">():</span>

<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Main entry point for training.  Select the dataset name and metadata, as</span>
<span class="sd">    well as model and training args, and you&#39;re off to the genomic races!</span>

<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># experiment settings:</span>
    <span class="n">ONLY_TEST</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span> <span class="c1">#50  # ~100 seems fine</span>
    <span class="n">max_length</span> <span class="o">=</span> <span class="mi">32768</span> <span class="c1">#160000  # max len of sequence of dataset (of what you want)</span>
    <span class="n">use_padding</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">5e-7</span>  <span class="c1"># Super small batch size -&gt; lower learning rate</span>
    <span class="n">rc_aug</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># reverse complement augmentation</span>
    <span class="n">add_eos</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># add end of sentence token</span>
    <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span>
    <span class="c1"># create datasets</span>

    <span class="n">train_fasta_file</span> <span class="o">=</span> <span class="s2">&quot;../inputs/DNA_sequences/training_boundaries.fasta&quot;</span>
    <span class="n">test_fasta_file</span> <span class="o">=</span> <span class="s2">&quot;../inputs/DNA_sequences/test_boundaries.fasta&quot;</span>
    <span class="n">train_csv_file</span> <span class="o">=</span> <span class="s2">&quot;../targets/training_targets.csv&quot;</span>
    <span class="n">test_csv_file</span> <span class="o">=</span> <span class="s2">&quot;../targets/test_targets.csv&quot;</span>

    <span class="c1">#max_length = 160000</span>
    <span class="n">N_BINS</span> <span class="o">=</span> <span class="mi">15</span> <span class="c1">#57</span>
    <span class="n">target_columns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}{</span><span class="n">cond</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">cond</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;_ctrl&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">N_BINS</span><span class="p">,</span> <span class="n">N_BINS</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

    <span class="c1"># for fine-tuning, only the &#39;tiny&#39; model can fit on colab</span>
    <span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s1">&#39;hyenadna-small-32k-seqlen&#39;</span> <span class="c1">#&#39;hyenadna-medium-160k-seqlen&#39;  # use None if training from scratch</span>
    <span class="c1">#model_name_or_path = &#39;./checkpoints/hyenadna-medium-160k-seqlen-custom/&#39;</span>
    <span class="c1"># we need these for the decoder head, if using</span>
    <span class="n">use_head</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># you can override with your own backbone config here if you want,</span>
    <span class="c1"># otherwise we&#39;ll load the HF one by default</span>
    <span class="n">backbone_cfg</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using device:&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>


    <span class="c1">#instantiate the model (pretrained here)</span>
    <span class="k">if</span> <span class="n">pretrained_model_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;hyenadna-small-32k-seqlen&#39;</span><span class="p">]:</span> <span class="c1">#[&#39;hyenadna-medium-160k-seqlen&#39;]:</span>
        <span class="c1"># use the pretrained Huggingface wrapper instead</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Here&#39;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">HyenaDNAPreTrainedModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="s1">&#39;../checkpoints/&#39;</span><span class="p">,</span>
            <span class="n">pretrained_model_name</span><span class="p">,</span>
            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">backbone_cfg</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">use_head</span><span class="o">=</span><span class="n">use_head</span><span class="p">,</span>
            <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># from scratch</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">HyenaDNAModel</span><span class="p">(</span><span class="o">**</span><span class="n">backbone_cfg</span><span class="p">,</span> <span class="n">use_head</span><span class="o">=</span><span class="n">use_head</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span>

    <span class="c1"># backbone_cfg = json.load(open(os.path.join(model_name_or_path, &#39;config.json&#39;)))</span>
    <span class="c1"># model = HyenaDNAModel(**backbone_cfg, use_head=use_head, n_classes=n_classes)</span>
    <span class="c1">#print(torch.cuda.memory_allocated(device=device))</span>

    <span class="c1"># create tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CharacterTokenizer</span><span class="p">(</span>
        <span class="n">characters</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">],</span>  <span class="c1"># add DNA characters, N is uncertain</span>
        <span class="n">model_max_length</span><span class="o">=</span><span class="n">max_length</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># to account for special tokens, like EOS</span>
        <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># we handle special tokens elsewhere</span>
        <span class="n">padding_side</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="c1"># since HyenaDNA is causal, we pad on the left</span>
    <span class="p">)</span>


    <span class="n">ds_train</span> <span class="o">=</span> <span class="n">CLASTER_HYENA_Dataset</span><span class="p">(</span><span class="n">train_fasta_file</span><span class="p">,</span>
        <span class="n">train_csv_file</span><span class="p">,</span>
        <span class="n">max_length</span><span class="p">,</span>
        <span class="n">target_columns</span><span class="p">,</span>
        <span class="n">d_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># No need for default here, it will be inferred from target_columns</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">tokenizer_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">use_padding</span><span class="o">=</span><span class="n">use_padding</span><span class="p">,</span>
        <span class="n">add_eos</span><span class="o">=</span><span class="n">add_eos</span><span class="p">,</span>
        <span class="n">rc_aug</span><span class="o">=</span><span class="n">rc_aug</span><span class="p">,</span>
        <span class="n">return_augs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">ds_test</span> <span class="o">=</span> <span class="n">CLASTER_HYENA_Dataset</span><span class="p">(</span><span class="n">test_fasta_file</span><span class="p">,</span>
        <span class="n">test_csv_file</span><span class="p">,</span>
        <span class="n">max_length</span><span class="p">,</span>
        <span class="n">target_columns</span><span class="p">,</span>
        <span class="n">d_output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># No need for default here, it will be inferred from target_columns</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">tokenizer_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">use_padding</span><span class="o">=</span><span class="n">use_padding</span><span class="p">,</span>
        <span class="n">add_eos</span><span class="o">=</span><span class="n">add_eos</span><span class="p">,</span>
        <span class="n">rc_aug</span><span class="o">=</span><span class="n">rc_aug</span><span class="p">,</span>
        <span class="n">return_augs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># loss function</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SmoothL1Loss</span><span class="p">()</span>

    <span class="c1"># create optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># nvidia_smi.nvmlInit()</span>
    <span class="c1"># deviceCount = nvidia_smi.nvmlDeviceGetCount()</span>
    <span class="c1"># for i in range(deviceCount):</span>
    <span class="c1">#     handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)</span>
    <span class="c1">#     util = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)</span>
    <span class="c1">#     mem = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)</span>
    <span class="c1">#     print(f&quot;|Device {i}| Mem Free: {mem.free/1024**2:5.2f}MB / {mem.total/1024**2:5.2f}MB | gpu-util: {util.gpu/100.0:3.1%} | gpu-mem: {util.memory/100.0:3.1%} |&quot;)</span>

    <span class="c1"># print(torch.cuda.memory_allocated(device=device))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">ONLY_TEST</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
            <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;../checkpoints/hyenadna-small-32k-seqlen/model_32k.pt&#39;</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>


<span class="c1">######################################################################################################################################</span>
<span class="c1">#@title Single example</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">PreTrainedModel</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">PretrainedConfig</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>



<span class="k">def</span> <span class="nf">inference_single_sequential</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">savepath</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">checkpoint_folder</span><span class="p">:</span> <span class="nb">str</span> <span class="p">):</span>

<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    this selects which backbone to use, and grabs weights/ config from HF</span>
<span class="sd">    4 options:</span>
<span class="sd">      &#39;hyenadna-tiny-1k-seqlen&#39;   # fine-tune on colab ok</span>
<span class="sd">      &#39;hyenadna-small-32k-seqlen&#39;</span>
<span class="sd">      &#39;hyenadna-medium-160k-seqlen&#39;  # inference only on colab</span>
<span class="sd">      &#39;hyenadna-medium-450k-seqlen&#39;  # inference only on colab</span>
<span class="sd">      &#39;hyenadna-large-1m-seqlen&#39;  # inference only on colab</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># you only need to select which model to use here, we&#39;ll do the rest!</span>
    <span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s1">&#39;hyenadna-medium-160k-seqlen&#39;</span> <span class="c1">#&#39;hyenadna-tiny-1k-seqlen&#39;# &#39;hyenadna-medium-450k-seqlen&#39;</span>

    <span class="n">max_lengths</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;hyenadna-tiny-1k-seqlen&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="s1">&#39;hyenadna-small-32k-seqlen&#39;</span><span class="p">:</span> <span class="mi">32768</span><span class="p">,</span>
        <span class="s1">&#39;hyenadna-medium-160k-seqlen&#39;</span><span class="p">:</span> <span class="mi">160000</span><span class="p">,</span>
        <span class="s1">&#39;hyenadna-medium-450k-seqlen&#39;</span><span class="p">:</span> <span class="mi">450000</span><span class="p">,</span>  <span class="c1"># T4 up to here</span>
        <span class="s1">&#39;hyenadna-large-1m-seqlen&#39;</span><span class="p">:</span> <span class="mi">1_000_000</span><span class="p">,</span>  <span class="c1"># only A100 (paid tier)</span>
    <span class="p">}</span>

    <span class="n">max_length</span> <span class="o">=</span> <span class="n">max_lengths</span><span class="p">[</span><span class="n">pretrained_model_name</span><span class="p">]</span>  <span class="c1"># auto selects</span>

    <span class="c1"># data settings:</span>
    <span class="n">use_padding</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">rc_aug</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># reverse complement augmentation</span>
    <span class="n">add_eos</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># add end of sentence token</span>

    <span class="c1"># we need these for the decoder head, if using</span>
    <span class="n">use_head</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># not used for embeddings only</span>

    <span class="c1"># you can override with your own backbone config here if you want,</span>
    <span class="c1"># otherwise we&#39;ll load the HF one in None</span>
    <span class="n">backbone_cfg</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using device:&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># instantiate the model (pretrained here)</span>
    <span class="k">if</span> <span class="n">pretrained_model_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;hyenadna-tiny-1k-seqlen&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;hyenadna-small-32k-seqlen&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;hyenadna-medium-160k-seqlen&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;hyenadna-medium-450k-seqlen&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;hyenadna-large-1m-seqlen&#39;</span><span class="p">]:</span>
        <span class="c1"># use the pretrained Huggingface wrapper instead</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">HyenaDNAPreTrainedModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">checkpoint_folder</span><span class="p">,</span>
            <span class="n">pretrained_model_name</span><span class="p">,</span>
            <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">backbone_cfg</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">use_head</span><span class="o">=</span><span class="n">use_head</span><span class="p">,</span>
            <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># from scratch</span>
    <span class="k">elif</span> <span class="n">pretrained_model_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">HyenaDNAModel</span><span class="p">(</span><span class="o">**</span><span class="n">backbone_cfg</span><span class="p">,</span> <span class="n">use_head</span><span class="o">=</span><span class="n">use_head</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span>

    <span class="c1"># create tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CharacterTokenizer</span><span class="p">(</span>
        <span class="n">characters</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">],</span>  <span class="c1"># add DNA characters, N is uncertain</span>
        <span class="n">model_max_length</span><span class="o">=</span><span class="n">max_length</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># to account for special tokens, like EOS</span>
        <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># we handle special tokens elsewhere</span>
        <span class="n">padding_side</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="c1"># since HyenaDNA is causal, we pad on the left</span>
    <span class="p">)</span>

    <span class="c1">#### Get named embeddings ####</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;&gt;&#39;</span><span class="p">:</span>
                <span class="n">seq_id</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">seq</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="n">rev_seq</span> <span class="o">=</span> <span class="n">string_reverse_complement</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">seq_name</span><span class="p">,</span><span class="n">sequence</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">seq_id</span><span class="p">,</span> <span class="n">seq_id</span> <span class="o">+</span> <span class="s1">&#39;_flipped&#39;</span><span class="p">],[</span><span class="n">seq</span><span class="p">,</span> <span class="n">rev_seq</span><span class="p">]):</span>
                    <span class="n">savefile</span> <span class="o">=</span> <span class="n">savepath</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">seq_name</span><span class="si">}</span><span class="s2">.npy&quot;</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">savefile</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
                        <span class="c1">#sequence = &#39;ACTG&#39; * int(max_length/4)</span>
                        <span class="n">tok_seq</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
                        <span class="n">tok_seq</span> <span class="o">=</span> <span class="n">tok_seq</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>  <span class="c1"># grab ids</span>

                        <span class="c1"># place on device, convert to tensor</span>
                        <span class="n">tok_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">tok_seq</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># unsqueeze for batch dim</span>
                        <span class="n">tok_seq</span> <span class="o">=</span> <span class="n">tok_seq</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                        <span class="c1"># prep model and forward</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
                            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tok_seq</span><span class="p">)</span> 
                            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
                            <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">embeddings</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">embeddings</span><span class="p">))</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">savepath</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">seq_name</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">,</span><span class="n">embeddings</span><span class="p">)</span>  <span class="c1"># embeddings here!</span>


<span class="c1">################################################################################</span>
<span class="c1">######################### S C R I P T ##########################################</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;../inputs/DNA_sequences/&quot;</span><span class="p">)</span>
<span class="n">filename</span> <span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;test_boundaries.fasta&quot;</span>
<span class="n">savepath</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;../inputs/DNA_sequences/test_embeddings_Hyena-DNA/&quot;</span><span class="p">)</span>
<span class="n">savepath</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">checkpoint_folder</span> <span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;../checkpoints/&quot;</span>
<span class="c1">#Path(checkpoint_folder).mkdir(parents=True, exist_ok=True)</span>


<span class="c1"># Uncomment if we want to get pretrained embeddings</span>
<span class="n">inference_single_sequential</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">savepath</span><span class="p">,</span> <span class="n">checkpoint_folder</span><span class="p">)</span>

<span class="c1"># Uncomment if we want to train and test HyenaDNA:</span>
<span class="c1">#run_train_CLASTER_HYENA()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting Hyena_DNA_Esrum.py
</pre></div>
</div>
</div>
</div>
</section>
<section id="enformer">
<h2>2. Enformer<a class="headerlink" href="#enformer" title="Link to this heading">#</a></h2>
<p>The original paper can be found as:</p>
<p>Avsec, Ž., Agarwal, V., Visentin, D. et al. Effective gene expression prediction from sequence by integrating long-range interactions. Nat Methods 18, 1196–1203 (2021). https://doi.org/10.1038/s41592-021-01252-x . In the case of the Enformer, we simply obtained the embeddings from the pretrained model matching our sequences.</p>
<p>Code to build the Enformer using pytorch and load pretrained weights was obtained from:
https://github.com/lucidrains/enformer-pytorch.</p>
<blockquote>
<div><p>KUDOS: Huge kudos to Phil Wang (lucidrains) for open sourcing the pytorch version of the Enformer</p>
</div></blockquote>
<p><strong>Install the Enformer pytorch package:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>enformer-pytorch&gt;<span class="o">=</span><span class="m">0</span>.5
</pre></div>
</div>
</div>
</div>
<p><strong>Get Enformer embeddings</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> Enformer_GPU.py

<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">enformer_pytorch</span> <span class="kn">import</span> <span class="n">from_pretrained</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Set the device to GPU if available</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># Load the model globally and move it to the specified device</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;EleutherAI/enformer-official-rough&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1">###### Functions #######</span>

<span class="k">def</span> <span class="nf">pad_tensor_symmetrically</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_length</span><span class="p">,</span> <span class="n">pad_value</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">160000</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input tensor must have shape (1, 160000)&quot;</span><span class="p">)</span>

    <span class="n">total_padding</span> <span class="o">=</span> <span class="n">target_length</span> <span class="o">-</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">padding_per_side</span> <span class="o">=</span> <span class="n">total_padding</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">padded_tensor</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">padding_per_side</span><span class="p">,</span> <span class="n">padding_per_side</span><span class="p">),</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">pad_value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">padded_tensor</span>

<span class="k">def</span> <span class="nf">map_dna_to_numeric_tensor</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
    <span class="n">mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
    <span class="n">numeric_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="n">mapping</span><span class="p">[</span><span class="n">nucleotide</span><span class="p">]</span> <span class="k">for</span> <span class="n">nucleotide</span> <span class="ow">in</span> <span class="n">sequence</span> <span class="k">if</span> <span class="n">nucleotide</span> <span class="ow">in</span> <span class="n">mapping</span><span class="p">]</span>
    <span class="n">sequence_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">numeric_sequence</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sequence_tensor</span>

<span class="n">string_complement_map</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">:</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">:</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">string_reverse_complement</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">string_complement_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">base</span><span class="p">)</span> <span class="k">for</span> <span class="n">base</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">seq</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">process_sequence</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">seq_id</span><span class="p">,</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">savepath</span><span class="p">):</span>
    <span class="n">rev_seq</span> <span class="o">=</span> <span class="n">string_reverse_complement</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">seq_name</span><span class="p">,</span> <span class="n">seq</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">seq_id</span><span class="p">,</span> <span class="n">seq_id</span><span class="p">[:</span><span class="o">-</span><span class="mi">8</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;_rev&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">sequence</span><span class="p">,</span> <span class="n">rev_seq</span><span class="p">]):</span>
        <span class="n">savefile</span> <span class="o">=</span> <span class="n">savepath</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">seq_name</span><span class="si">}</span><span class="s2">.npy&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">savefile</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
            <span class="n">seq_tensor</span> <span class="o">=</span> <span class="n">map_dna_to_numeric_tensor</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
            <span class="n">seq_tensor</span> <span class="o">=</span> <span class="n">pad_tensor_symmetrically</span><span class="p">(</span><span class="n">seq_tensor</span><span class="p">,</span> <span class="n">target_length</span><span class="o">=</span><span class="mi">196608</span><span class="p">)</span>
            <span class="n">seq_tensor</span> <span class="o">=</span> <span class="n">seq_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move data to GPU</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">seq_tensor</span><span class="p">,</span> <span class="n">return_embeddings</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Move data back to CPU for saving</span>
            <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">savefile</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">create_Enformer_embeddings</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">savepath</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">/</span> <span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;&gt;&#39;</span><span class="p">):</span>
                <span class="n">seq_id</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">seq</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="n">process_sequence</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">seq_id</span><span class="p">,</span> <span class="n">seq</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>

<span class="c1">#### Main script ####</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;../inputs/DNA_sequences/&quot;</span><span class="p">)</span>
<span class="n">split_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">split_list</span><span class="p">:</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">_boundaries.fasta&quot;</span>
    <span class="n">savepath</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;../inputs/DNA_sequences/</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">_embeddings_Enformer/&quot;</span><span class="p">)</span>
    <span class="n">savepath</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">create_Enformer_embeddings</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting Enformer_GPU.py
</pre></div>
</div>
</div>
</div>
<p>We can now run it as a python file in a slurm based system. We will greatly benefit from the multiprocessing functionality.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>srun<span class="w"> </span>--<span class="w"> </span>python<span class="w"> </span>Enformer.py
</pre></div>
</div>
<p><strong>Train and test head on top of embeddings</strong></p>
<p>The added model is the same as the decoder/ model head we used for Hyena, except that we skip the initial sequence dimensionality reduction because the embeddings are already provided in bins of 128 bp.</p>
<blockquote>
<div><p><em>Note: The test set is quite large. I predicted it all at once using 100 CPUs, but the code can be splitted to predict in batches and join the predictions afterwards if needed. Additionally, I removed all reversed (duplicated) samples from inputs and targets for test predictions to match those of Hyena.</em></p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> Enformer_head.py

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1">#from sklearn.metrics import r2_score</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1">###### Data class and head Model ######################</span>
<span class="k">class</span> <span class="nc">EnformerHeadDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class reads input numpy arrays and target csv files and returns input-target torch tensors.</span>
<span class="sd">    Args:</span>
<span class="sd">        - data_folder: Directory containing our input files stored as separate numpy arrays (sampleID.npy).</span>
<span class="sd">        - targets_file: CSV file containing the IDs of the samples and their corresponding targets.</span>
<span class="sd">        - N_kbp: Number of kilobase pairs from TSS to include in the target arrays. For example, N_kbp = 32 means targets from -32 kbp to +32 kbp.</span>
<span class="sd">        - stack_type: &quot;hstack&quot; or &quot;vstack&quot; for the concatenation method of control and treated target arrays.</span>
<span class="sd">    Returns:</span>
<span class="sd">        - Input or data tensor.</span>
<span class="sd">        - Target tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_folder</span><span class="p">,</span> <span class="n">targets_file</span><span class="p">,</span> <span class="n">stack_type</span><span class="p">,</span> <span class="n">bin_size</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">data_folder</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;The specified data folder does not exist: </span><span class="si">{</span><span class="n">data_folder</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">stack_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;hstack&quot;</span><span class="p">,</span> <span class="s2">&quot;vstack&quot;</span><span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;Invalid stack type: </span><span class="si">{</span><span class="n">stack_type</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_folder</span> <span class="o">=</span> <span class="n">data_folder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_type</span> <span class="o">=</span> <span class="n">stack_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bin_size</span> <span class="o">=</span> <span class="n">bin_size</span>
        <span class="n">targets_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">targets_file</span><span class="p">)</span>

        
        <span class="n">ctrl_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">targets_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s2">&quot;ctrl&quot;</span> <span class="ow">in</span> <span class="n">col</span><span class="p">]</span>
        <span class="n">treated_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">targets_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="s2">&quot;treated&quot;</span> <span class="ow">in</span> <span class="n">col</span><span class="p">]</span>

        <span class="c1"># Filter out targets for which input files do not exist and separate control and treated targets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_info</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">targets_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">sample_id</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">]</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_id</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
                <span class="n">ctrl_target</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">ctrl_cols</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
                <span class="n">treated_target</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="n">treated_cols</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sample_info</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">ctrl_target</span><span class="p">,</span> <span class="n">treated_target</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_info</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">sample_name</span><span class="p">,</span> <span class="n">ctrl_target</span><span class="p">,</span> <span class="n">treated_target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_info</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_folder</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_name</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

        <span class="c1"># Stack the targets based on stack_type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_type</span> <span class="o">==</span> <span class="s2">&quot;hstack&quot;</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ctrl_target</span><span class="p">,</span> <span class="n">treated_target</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># vstack</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">ctrl_target</span><span class="p">,</span> <span class="n">treated_target</span><span class="p">))</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DNAConvNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_depth</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_conditions</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DNAConvNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">input_depth</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">n_conditions</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>  <span class="c1"># Adding the Softplus activation layer as in Enformer</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># (64, 3072,896)</span>
        <span class="c1"># Apply dropout to the input</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Applying softplus activation after convolution</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">DNAConvandDense</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_depth</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">,</span> <span class="n">hidden_depth</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DNAConvandDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">input_depth</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">hidden_depth</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">)</span>
        
        <span class="c1"># Calculate the output length after convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_length_after_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_output_length</span><span class="p">(</span><span class="n">input_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>
        
        <span class="c1"># Fully connected layer with calculated input size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_depth</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length_after_conv</span><span class="p">,</span> <span class="n">output_length</span><span class="p">)</span>
        
        <span class="c1"># Softplus activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">calculate_output_length</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">input_length</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">-</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># (64, 3072,896)</span>
        <span class="c1"># Apply 1D convolution</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Apply dropout to the input</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Flatten the convolution output</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Pass through the fully connected layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Apply Softplus activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">ConvLinearModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_depth</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">output_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">,</span> <span class="n">hidden_depth</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvLinearModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 2D Average Pooling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">avg_pool_size</span><span class="p">)</span>

        <span class="c1"># Dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>

        <span class="c1"># Adjust the input depth and sequence length based on the 2D pooling</span>
        <span class="n">new_depth</span> <span class="o">=</span> <span class="n">input_depth</span> <span class="o">//</span> <span class="n">avg_pool_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">new_seq_length</span> <span class="o">=</span> <span class="n">input_length</span> <span class="o">//</span> <span class="n">avg_pool_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># 1D Convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">new_depth</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">hidden_depth</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">)</span>

        <span class="c1"># Calculate the output length after convolution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_length_after_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_output_length</span><span class="p">(</span><span class="n">new_seq_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>
        
        <span class="c1"># Fully connected layer with calculated input size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_depth</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length_after_conv</span><span class="p">,</span> <span class="n">output_length</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">calculate_output_length</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">input_length</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">-</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Reshape x to (batch_size, 1, input_depth, seq_length) for 2D avg pooling</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> 
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># Reshape back to (batch_size, new_depth, new_seq_length) for 1D convolution</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>

        <span class="c1"># Apply dropout to the inputs of the convolutions</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Apply 1D convolution</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Apply dropout to the inputs of the final layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Reshape x for the linear layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Pass through the fully connected layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Apply Softplus activation</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="c1">#### Custom loss #############</span>
<span class="k">class</span> <span class="nc">ZIPLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">.02</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZIPLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>  <span class="c1"># Iterate over channels</span>
            <span class="n">lambda_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">logit_zero</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span>

            <span class="c1"># Adjust for non-true zeros</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">target</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">target</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>

            <span class="c1"># Poisson loss part</span>
            <span class="n">poisson_loss</span> <span class="o">=</span> <span class="n">lambda_</span> <span class="o">-</span> <span class="n">target</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lambda_</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

            <span class="c1"># Zero-inflation part</span>
            <span class="n">zero_inflation_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logit_zero</span><span class="p">)</span>
            <span class="n">zero_inflation_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">zero_inflation_prob</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">),</span>
                                               <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">zero_inflation_prob</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>

            <span class="c1"># Combine the Poisson and zero-inflation losses for this channel</span>
            <span class="n">channel_loss</span> <span class="o">=</span> <span class="n">zero_inflation_loss</span> <span class="o">+</span> <span class="n">poisson_loss</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">channel_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Average loss over channels</span>

<span class="k">class</span> <span class="nc">ZINBLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dispersion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">zero_inflation_prob</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">channel_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Zero-Inflated Negative Binomial loss module for multi-channel data with predefined extra parameters.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - dispersion: Optional, predefined dispersion parameter (alpha) for the negative binomial distribution.</span>
<span class="sd">                      Can be a scalar or a tensor with shape (channel,).</span>
<span class="sd">        - zero_inflation_prob: Optional, predefined tensor of zero-inflation probabilities with shape (batch_size, channel, seq_length).</span>
<span class="sd">        - channel_weights: Optional tensor with shape (channel,) representing the weight of each channel in the loss calculation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZINBLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-10</span>

        <span class="k">if</span> <span class="n">dispersion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;dispersion&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dispersion</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;dispersion&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">zero_inflation_prob</span> <span class="o">=</span> <span class="n">zero_inflation_prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channel_weights</span> <span class="o">=</span> <span class="n">channel_weights</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">true_counts</span><span class="p">,</span> <span class="n">predicted_counts</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">seq_length</span> <span class="o">=</span> <span class="n">true_counts</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">channel_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">channel_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">true_counts</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">channel_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">channel_weights</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">zero_inflation_prob</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">zero_inflation_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">predicted_counts</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">zero_inflation_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">zero_inflation_prob</span>

        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">for</span> <span class="n">channel</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_channels</span><span class="p">):</span>
            <span class="c1"># Extract data for the current channel</span>
            <span class="n">true_counts_channel</span> <span class="o">=</span> <span class="n">true_counts</span><span class="p">[:,</span> <span class="n">channel</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">predicted_counts_channel</span> <span class="o">=</span> <span class="n">predicted_counts</span><span class="p">[:,</span> <span class="n">channel</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">predicted_zero_inflation_channel</span> <span class="o">=</span> <span class="n">zero_inflation_prob</span><span class="p">[:,</span> <span class="n">channel</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">dispersion_channel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dispersion</span><span class="p">[</span><span class="n">channel</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dispersion</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">dispersion</span>

            <span class="c1"># Negative Binomial term</span>
            <span class="n">theta_channel</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">dispersion_channel</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
            <span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">true_counts_channel</span> <span class="o">+</span> <span class="n">theta_channel</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">theta_channel</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">true_counts_channel</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">t2</span> <span class="o">=</span> <span class="p">(</span><span class="n">theta_channel</span> <span class="o">+</span> <span class="n">true_counts_channel</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">predicted_counts_channel</span> <span class="o">/</span> <span class="n">theta_channel</span><span class="p">)</span> <span class="o">+</span> <span class="n">true_counts_channel</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta_channel</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">predicted_counts_channel</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>

            <span class="n">nb_term</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">+</span> <span class="n">t2</span>

            <span class="c1"># Zero-Inflation term</span>
            <span class="n">zero_inflation_term</span> <span class="o">=</span> <span class="n">predicted_zero_inflation_channel</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="o">-</span><span class="n">predicted_zero_inflation_channel</span> <span class="o">-</span> <span class="n">nb_term</span><span class="p">)</span> <span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="o">-</span><span class="n">nb_term</span><span class="p">)</span>

            <span class="c1"># Combine terms</span>
            <span class="n">zero_inflation_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_counts_channel</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">channel_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">zero_inflation_term</span> <span class="o">*</span> <span class="n">zero_inflation_mask</span> <span class="o">+</span> <span class="n">nb_term</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">zero_inflation_mask</span><span class="p">))</span>

            <span class="c1"># Weighted sum of the channel losses</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">channel_weights</span><span class="p">[</span><span class="n">channel</span><span class="p">]</span> <span class="o">*</span> <span class="n">channel_loss</span>

        <span class="c1"># Average loss over channels</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">num_channels</span>

        <span class="k">return</span> <span class="n">loss</span>
<span class="c1">############## Training and auxilliary functions ##############</span>


<span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">trainable_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_params</span><span class="p">,</span> <span class="n">trainable_params</span>

<span class="k">def</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to compute R2 coefficient between predictions and targets.</span>
<span class="sd">    This allows for all operations to happen in the GPU )if available)</span>
<span class="sd">    without moving back and forth to the CPU.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">target_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
    <span class="n">ss_tot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">targets</span> <span class="o">-</span> <span class="n">target_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">ss_res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">targets</span> <span class="o">-</span> <span class="n">outputs</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ss_res</span> <span class="o">/</span> <span class="n">ss_tot</span>
    <span class="k">return</span> <span class="n">r2</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Train and validate the model</span>
<span class="k">def</span> <span class="nf">train_with_validation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">savepath</span><span class="p">):</span>
    <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">val_accuracies</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training the model&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_r2</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="c1"># Initialize progress bar</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="c1"># Send data to GPU</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="c1"># Calculate R^2 score</span>
            <span class="n">total_r2</span> <span class="o">+=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># Update progress bar</span>
            <span class="n">progress_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>

        <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">count</span>
        <span class="n">avg_train_r2</span> <span class="o">=</span> <span class="n">total_r2</span> <span class="o">/</span> <span class="n">count</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span>
        <span class="n">train_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_train_r2</span><span class="p">)</span>

        <span class="c1"># Validation step</span>
        <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_r2</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
        <span class="n">val_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_r2</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">], Training Loss: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Training R^2: </span><span class="si">{</span><span class="n">avg_train_r2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Validation Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Validation R^2: </span><span class="si">{</span><span class="n">val_r2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Close the progress bar at the end of the epoch</span>
        <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># Save the final model</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">savepath</span> <span class="o">/</span> <span class="s1">&#39;model_smoothl1.pt&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">val_accuracies</span>


<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_r2</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_r2</span> <span class="o">+=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">count</span>
    <span class="n">avg_r2</span> <span class="o">=</span> <span class="n">total_r2</span> <span class="o">/</span> <span class="n">count</span>
    <span class="k">return</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="n">avg_r2</span>

<span class="k">def</span> <span class="nf">plot_losses_accuracies</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">val_accuracies</span><span class="p">,</span> <span class="n">savepath</span><span class="p">):</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Plotting results&quot;</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Plot losses</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and Validation Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># Plot point-wise R2 evolution</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">train_accuracies</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span><span class="n">train_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training R²&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">val_accuracies</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">val_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation R²&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and Validation R² Score&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">savepath</span> <span class="o">/</span> <span class="s2">&quot;Reconstruction_metrics.png&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">test_model_with_predictions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">targets_list</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># if you also want to store true targets</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># No gradient calculation</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">targets_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>  <span class="c1"># if storing targets</span>

    <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets_list</span>
<span class="c1">########################## Script #########################</span>
<span class="c1"># Train model and test on unseen data</span>
<span class="n">IS_HYENA</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># We will not train on HyenaDNA&#39;s embeddings</span>
<span class="n">TRAIN</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">TEST</span> <span class="o">=</span> <span class="kc">True</span>
<span class="c1"># Paths:</span>
<span class="n">train_data_folder</span> <span class="o">=</span> <span class="s2">&quot;../inputs/DNA_sequences/training_embeddings_Enformer/&quot;</span>
<span class="n">val_data_folder</span> <span class="o">=</span> <span class="s2">&quot;../inputs/DNA_sequences/validation_embeddings_Enformer/&quot;</span>
<span class="n">test_data_folder</span> <span class="o">=</span> <span class="s2">&quot;../inputs/DNA_sequences/test_embeddings_Enformer/&quot;</span>

<span class="n">targets_file</span> <span class="o">=</span> <span class="s1">&#39;../targets/training_targets_Enformer.csv&#39;</span>
<span class="n">test_targets_file</span> <span class="o">=</span> <span class="s1">&#39;../targets/test_targets_Enformer.csv&#39;</span>
<span class="c1">#savepath = Path(&quot;./results/&quot;)</span>
<span class="n">savepath</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;../benchmarks/Enformer/&quot;</span><span class="p">)</span>
<span class="n">savepath</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Hyperparameters:</span>
<span class="n">input_length</span> <span class="o">=</span> <span class="mi">896</span> <span class="c1"># Embeddings add 2 characters to the 160kbp long sequences</span>
<span class="n">input_depth</span> <span class="o">=</span> <span class="mi">3072</span>
<span class="n">hidden_depth</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">115</span> <span class="c1"># 57kbp per side #input_length</span>
<span class="n">n_conditions</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">stack_type</span> <span class="o">=</span> <span class="s1">&#39;hstack&#39;</span> <span class="c1">#&#39;vstack&#39; # vstack when outputting directly from convolutions</span>
<span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dilation</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span> <span class="c1"># proper padding</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="c1">#################</span>

<span class="k">if</span> <span class="n">IS_HYENA</span><span class="p">:</span>
    <span class="n">train_data_folder</span> <span class="o">=</span> <span class="s2">&quot;/projects/cbmr_shared/scratch/Hyena_DNA/training/&quot;</span>
    <span class="n">val_data_folder</span> <span class="o">=</span> <span class="s2">&quot;/projects/cbmr_shared/scratch/Hyena_DNA/validation/&quot;</span>
    <span class="n">test_data_folder</span> <span class="o">=</span> <span class="s2">&quot;/projects/cbmr_shared/scratch/Hyena_DNA/test/&quot;</span>

    <span class="n">targets_file</span> <span class="o">=</span> <span class="s1">&#39;/projects/cbmr_shared/scratch/Hyena_DNA/targets/benchmark_sequence_based_target_arrays_1kbp_57_bins_2_conditions_decareads_abs.csv&#39;</span>
    <span class="n">test_targets_file</span> <span class="o">=</span> <span class="s1">&#39;/projects/cbmr_shared/scratch/Hyena_DNA/targets/benchmark_sequence_based_target_arrays_1kbp_57_bins_2_conditions_test_decareads.csv&#39;</span>

    <span class="n">savepath</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/projects/cbmr_shared/scratch/Hyena_DNA/results/Hyena/&quot;</span><span class="p">)</span>
    <span class="n">savepath</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Hyperparameters: </span>
    <span class="n">input_length</span> <span class="o">=</span> <span class="mi">160002</span> <span class="c1"># Embeddings add 2 characters to the 160kbp long sequences</span>
    <span class="n">input_depth</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">hidden_depth</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">output_size</span> <span class="o">=</span> <span class="mi">115</span> <span class="c1"># 2 conditions from - N_kbt to + N_kbt (adding 0, central bin)</span>
    <span class="n">n_conditions</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">stack_type</span> <span class="o">=</span> <span class="s1">&#39;hstack&#39;</span> <span class="c1">#&#39;hstack&#39;</span>
    <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">9</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">333</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">dilation</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="mi">2</span>  

    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">avg_pool_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">.3</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-4</span>


<span class="c1"># Setup logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">savepath</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;/training.log&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> </span><span class="si">%(levelname)s</span><span class="s1">: </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Device:</span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DNAConvandDense</span><span class="p">(</span><span class="n">input_depth</span><span class="o">=</span><span class="n">input_depth</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">input_length</span><span class="p">,</span> <span class="n">output_length</span><span class="o">=</span><span class="n">n_conditions</span><span class="o">*</span><span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">hidden_depth</span><span class="o">=</span><span class="n">hidden_depth</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">if</span> <span class="n">IS_HYENA</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ConvLinearModel</span><span class="p">(</span><span class="n">input_depth</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">n_conditions</span><span class="o">*</span><span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">hidden_depth</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">total_params</span><span class="p">,</span> <span class="n">trainable_params</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total parameters: </span><span class="si">{</span><span class="n">total_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trainable parameters: </span><span class="si">{</span><span class="n">trainable_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">TRAIN</span><span class="p">:</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Beginning training&quot;</span><span class="p">)</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">EnformerHeadDataset</span><span class="p">(</span><span class="n">train_data_folder</span><span class="p">,</span> <span class="n">targets_file</span><span class="p">,</span> <span class="n">stack_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">EnformerHeadDataset</span><span class="p">(</span><span class="n">val_data_folder</span><span class="p">,</span> <span class="n">targets_file</span><span class="p">,</span> <span class="n">stack_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">SmoothL1Loss</span><span class="p">()</span> <span class="c1">#torch.nn.PoissonNLLLoss(log_input=False) #ZINBLoss() #zinb_loss_channelwise()#ZeroInflatedPoissonLoss() #torch.nn.PoissonNLLLoss(log_input=False)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">val_accuracies</span><span class="o">=</span> <span class="n">train_with_validation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">savepath</span><span class="o">=</span><span class="n">savepath</span><span class="p">)</span>
    <span class="n">plot_losses_accuracies</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">val_accuracies</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>

<span class="c1">############# Test predictions #############</span>
<span class="k">if</span> <span class="n">TEST</span><span class="p">:</span>
    <span class="c1">#device = torch.device(&quot;cpu&quot;)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Beginning test predictions&quot;</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;../benchmarks/Enformer/model_smoothl1.pt&quot;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">EnformerHeadDataset</span><span class="p">(</span><span class="n">test_data_folder</span><span class="p">,</span> <span class="n">test_targets_file</span><span class="p">,</span> <span class="n">stack_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">test_model_with_predictions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># Save Enformer predictions and targets in numpy arrays:</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">savepath</span> <span class="o">/</span> <span class="s2">&quot;enformer_test_predictions.npy&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="s2">&quot;False&quot;</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">savepath</span> <span class="o">/</span> <span class="s2">&quot;enformer_test_targets.npy&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="s2">&quot;False&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting Enformer_head.py
</pre></div>
</div>
</div>
</div>
<p>Now we can proceed to the data analysis!</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyena-dna">1. Hyena-DNA:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enformer">2. Enformer</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Marc Pielies Avelli
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022, Marc Pielies Avelli.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>